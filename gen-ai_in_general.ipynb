{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4ef8561",
   "metadata": {},
   "source": [
    "# Разрез современного Генеративного машинного обучения\n",
    "\n",
    "**темы:** основные понятия и механизмы генеративного ИИ, обзор современных методов обучения генеративного ИИ, этика применения, споры и юридические аспекты \n",
    "\n",
    "**дата:** 02.02.2026\n",
    "\n",
    "**Автор:** Федоров Артем Максимович"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ea5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefc99eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a86a5f4",
   "metadata": {},
   "source": [
    "## Вероятностное моделирование \"in general\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcc88db",
   "metadata": {},
   "source": [
    "Самой популярной парадигмой современного машинного обучения является вероятностное моделирование, подразумевающее, что наблюдаемые данные порождаются некоторым законом распределения, существующим «в природе» – сам закон нам не известен, но мы видим, какие данные могут им порождаться по наблюдаемой обучающей выборке.\n",
    "\n",
    "Таким образом мы формализуем неопределённость и шум реального мира: вместо “жёстких” правил мы строим модель, какие наблюдения типичны и насколько. Где выделяются \"частоты\"  явления, там совершенно натуральным образом появляется и определение вероятности – чем чаще объекты (или их окрестности) встречаются в данных, тем выше должна быть их “масса” в распределении. Такая постановка делает методы:\n",
    "\n",
    "- более робастными (устойчивыми к шуму в данных)\n",
    "- интерпретируемыми (теперь модель выделяет вероятность \"правильного\" ответа – своей уверенности)\n",
    "- более гибкими (появляется конструктивный подход построения/модернизции моделей, учитывающих разные аспекты данных/доменов)\n",
    "\n",
    "\n",
    "> **Пример распределения изображений** из двух классов (котики и собачки). Здесь показано, что в некоторой области расположены два концентрированных облака точек, каждое из которых определено под соответствующий класс изображений; обратите внимание, что точки существуют не только в центрах облаков, но и в удалении или между ними – это так же валидные объекты, просто менее похожие на \"идеальных\" представителей (усредненных) классов. \n",
    "<p align=\"center\">\n",
    "  <img src=\"images/lecture_1/cats_n_dogs_distribution.png\" style=\"width:60%;\">\n",
    "</p>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4785f6",
   "metadata": {},
   "source": [
    "#### Понятие распределения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba017d3",
   "metadata": {},
   "source": [
    "Пусть мы так или иначе изучаем объекты $x$, принадлежащие (погруженные) в множество `носитель` $x \\in \\mathcal{X}$ $\\Rightarrow$ любой наблюдаемый нами объект существует внутри данного множетсва $\\mathcal{X}$. Потребность в явном выделении такого понятия как `носитель` может быть неочевидно, однако оно полезно, когда $\\mathcal{X}$ сам по себе сложный объект. Это может быть:\n",
    "\n",
    "| Носитель $\\mathcal{X}$ | Определение | Примеры использования в ML |\n",
    "| --- | --- | --- |\n",
    "| $\\mathcal{X} \\equiv \\mathbb{R}^d$ | Евклидово пространство признаков | эмбеддинги текста/изображений, векторизованные тензоры (матрицы) |\n",
    "| $\\mathcal{X} \\equiv \\mathbb{H}^d$ | Гиперболическое пространство признаков | эмбеддинги объектов, сохраняющие доменную иерархию |\n",
    "| $\\mathcal{X} \\equiv \\mathbb{S}^d_{++}$ | Множество симметричных положительно определённых матриц | ковариационные матрицы в сигналов/EEG/fMRI, матрицы рассеяния в CV, Riemannian ML в оптимизации |\n",
    "| $\\mathcal{X} \\equiv \\mathcal{G}$ | Множество графов | молекулярная генерация (генеративные GNN), генерация/дополнение knowledge graphs, моделирование социальных/транспортных сетей |\n",
    "| $\\mathcal{X} \\equiv \\mathcal{M}^n$ | Множество ранжировок/перестановок | learning-to-rank (поисковая выдача), рекомендательные системы (перестановки товаров), генерация упорядоченных списков при наличии комбинаторных ограничений |\n",
    "| $\\mathcal{X} \\subset \\Delta^{K-1}=\\left\\{p\\in\\mathbb{R}^K_{\\ge 0}:\\sum_{k=1}^K p_k=1\\right\\}$ | Вероятностный симплекс (векторы вероятностей) | тематическое моделирование (LDA/Dirichlet), смеси распределений, распределения над действиями в RL (policy) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3759ffe2",
   "metadata": {},
   "source": [
    "Для фиксированного `носителя` $\\mathcal{X}$ мы можем ввести понятие `распределение` – закон, сопоставляющий каждой области $A \\subseteq \\mathcal{X}$ число $\\mathbb{P}(A) \\in [0, 1]$: вероятность того, что случайно выбранный объект $x$ окажется в этой области $$\\mathbb{P}(A) = \\mathbb{P}(\\textrm{Randomly Sampled:} \\,\\, x \\in A)$$\n",
    "\n",
    "Мы конструктивно определяем, в каких областях объекты существует и их появление/наблюдение там не редко (типично), а в каких областях $\\mathcal{X}$ концентрация минимальна (или вообще 0). У такого правила есть три базовых свойства:\n",
    "\n",
    "1) Неотрицательность: $\\mathbb{P}(A) \\leq 0$\n",
    "2) Нормировка: $\\mathbb{P}(\\mathcal{X})=1$ (вся масса распределения живёт на `носителе`)\n",
    "3) Аддитивность для непересекающихся областей: если $A \\cap B = \\varnothing$, то $\\mathbb{P}(A\\cup B)=\\mathbb{P}(A)+\\mathbb{P}(B)$\n",
    "\n",
    "Во многих задачах удобно описывать `распределение` не через вероятности областей напрямую, а через `плотность` $p(x)$ – мы требуем от `распределения` абсолютной непрерывности. Интуитивно $p(x)$ всюду на `носителе` $\\mathcal{X}$ определена и ее можно понимать как 'интенсивность массы' распределения в окрестности точки $x$ – с какой скоростью будет расти вероятность при увеличении маленькой области с центром в данной точке.\n",
    "Тогда вероятность того, что случайный объект $X$ попадёт в область $A \\subseteq \\mathcal{X}$, выражается интегрированием плотности по этой области:\n",
    "$$\\mathbb{P}(X \\in A) \\;=\\; \\int_{A} p(x)\\,dx \\quad\\mid\\quad \\int_{\\mathcal{X}} p(x)\\,dx \\;=\\; 1 $$\n",
    "\n",
    "> Пример бимодального (две вершины) абсолютно непрерывного распределения\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbefc21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "def mvn_pdf_grid(X, Y, mean, cov):\n",
    "    \"\"\"2D Gaussian density evaluated on a meshgrid (X, Y).\"\"\"\n",
    "    mean = np.asarray(mean, dtype=float).reshape(2,)\n",
    "    cov  = np.asarray(cov, dtype=float).reshape(2, 2)\n",
    "\n",
    "    pos  = np.stack([X, Y], axis=-1)               # (..., 2)\n",
    "    diff = pos - mean                              # (..., 2)\n",
    "\n",
    "    inv_cov = np.linalg.inv(cov)\n",
    "    det_cov = np.linalg.det(cov)\n",
    "\n",
    "    quad = np.einsum(\"...i,ij,...j->...\", diff, inv_cov, diff)\n",
    "    norm = 1.0 / (2.0 * np.pi * np.sqrt(det_cov))\n",
    "    return norm * np.exp(-0.5 * quad)\n",
    "\n",
    "def mvn_pdf_points(P, mean, cov):\n",
    "    \"\"\"2D Gaussian density evaluated at points P of shape (N,2).\"\"\"\n",
    "    mean = np.asarray(mean, dtype=float).reshape(2,)\n",
    "    cov  = np.asarray(cov, dtype=float).reshape(2, 2)\n",
    "\n",
    "    P = np.asarray(P, dtype=float)\n",
    "    diff = P - mean[None, :]\n",
    "\n",
    "    inv_cov = np.linalg.inv(cov)\n",
    "    det_cov = np.linalg.det(cov)\n",
    "\n",
    "    quad = np.einsum(\"ni,ij,nj->n\", diff, inv_cov, diff)\n",
    "    norm = 1.0 / (2.0 * np.pi * np.sqrt(det_cov))\n",
    "    return norm * np.exp(-0.5 * quad)\n",
    "\n",
    "# --- Mixture parameters ---\n",
    "w1, w2 = 0.5, 0.5\n",
    "mu1 = np.array([-1.5, -1.0])\n",
    "mu2 = np.array([ 1.5,  1.2])\n",
    "\n",
    "# updated covariances (your values)\n",
    "cov1 = np.array([[0.6,  0.2],\n",
    "                 [0.2,  0.8]])\n",
    "\n",
    "cov2 = np.array([[1.12, -0.25],\n",
    "                 [-0.25, 1.15]])\n",
    "\n",
    "# --- Grid for surface ---\n",
    "xmin, xmax = -5, 5\n",
    "ymin, ymax = -5, 5\n",
    "n = 260\n",
    "\n",
    "x = np.linspace(xmin, xmax, n)\n",
    "y = np.linspace(ymin, ymax, n)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "Z = w1 * mvn_pdf_grid(X, Y, mu1, cov1) + w2 * mvn_pdf_grid(X, Y, mu2, cov2)\n",
    "\n",
    "# --- Sampling 200 points from the mixture ---\n",
    "rng = np.random.default_rng(42)\n",
    "N = 200\n",
    "comp = rng.choice([0, 1], size=N, p=[w1, w2])\n",
    "\n",
    "samples = np.empty((N, 2))\n",
    "n1 = np.sum(comp == 0)\n",
    "n2 = N - n1\n",
    "\n",
    "# --- Plot ---\n",
    "fig = plt.figure(figsize=(11, 8), dpi=150)\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# surface (transparent)\n",
    "ax.plot_surface(\n",
    "    X, Y, Z,\n",
    "    rstride=1, cstride=1,\n",
    "    linewidth=0,\n",
    "    antialiased=True,\n",
    "    alpha=0.55,\n",
    "    shade=True\n",
    ")\n",
    "\n",
    "# wireframe overlay (grid visible on modes too)\n",
    "ax.plot_wireframe(\n",
    "    X, Y, Z,\n",
    "    rstride=10, cstride=10,\n",
    "    linewidth=0.6,\n",
    "    alpha=0.75\n",
    ")\n",
    "\n",
    "z0 = 0.0\n",
    "ax.contour(X, Y, Z, zdir=\"z\", offset=z0, levels=12, alpha=0.55)\n",
    "\n",
    "# labels / limits / view\n",
    "ax.set_title(\"Bimodal Gaussian Mixture Density (2 Gaussians)\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "ax.set_zlabel(\"p(x, y)\", labelpad=14)   # <- help z-label readability\n",
    "\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.set_zlim(z0, float(Z.max()) * 1.08)\n",
    "\n",
    "ax.view_init(elev=28, azim=-55)\n",
    "\n",
    "# cleaner panes\n",
    "ax.xaxis.pane.set_alpha(0.0)\n",
    "ax.yaxis.pane.set_alpha(0.0)\n",
    "ax.zaxis.pane.set_alpha(0.0)\n",
    "fig.subplots_adjust(left=0.02, right=0.86, bottom=0.02, top=0.92)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf1038",
   "metadata": {},
   "source": [
    "#### Случайные величины\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e136e21a",
   "metadata": {},
   "source": [
    "\n",
    "**Подход теории вероятностей:** в основе лежит идея, что существует пространство элементарных исходов $\\Omega$ и закон вероятности на нём. Случайная величина $X\\in\\mathcal{X}$ — это отображение, которое каждому исходу $\\omega\\in\\Omega$ сопоставляет наблюдаемый объект $x=X(\\omega)\\in\\mathcal{X}$; тем самым $X$ «переносит» вероятностный закон с $\\Omega$ на пространство данных $\\mathcal{X}$, порождая распределение $P_X$ (или плотность $p_X$ в непрерывном случае): $\\mathbb{P}(X\\in A)=P_X(A)$ для областей $A\\subseteq\\mathcal{X}$, а при наличии плотности $P_X(A)=\\int_A p_X(x),dx$ и $\\int_{\\mathcal{X}} p_X(x),dx=1$.\n",
    "\n",
    "**Эмпирический подход:** если опустить формальное определение, то случайная величина — это переменная, значение которой не фиксировано заранее: при разных повторениях наблюдения мы получаем разные реализации $x$. Набор наблюдений ${x_i}_{i=1}^n$ можно рассматривать как сэмплы из некоторого распределения $P_X$ (часто пишут $x_i\\sim P_X$), которое и описывает, какие значения встречаются чаще, а какие реже.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912dc39a",
   "metadata": {},
   "source": [
    "#### Условное распределение\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6f889f",
   "metadata": {},
   "source": [
    "\n",
    "Пусть мы наблюдаем пару $(x,y)\\in\\mathcal{X}\\times\\mathcal{Y}$ как один сэмпл из некоторого *совместного распределения* $p(x,y)$ на носителе $\\mathcal{X}\\times\\mathcal{Y}$.\n",
    "\n",
    "Тогда *условное распределение* $p(y\\mid x)$ отвечает на вопрос:\n",
    "$$\n",
    "p(y\\mid x)\\ \\text{--- как распределён } y,\\ \\text{если наблюдение } x \\text{ зафиксировано.}\n",
    "$$\n",
    "\n",
    "Иначе говоря, при фиксированном $x$ функция $p(\\cdot\\mid x)$ задаёт распределение возможных значений $y$: она показывает, какие $y$ более типичны (имеют большую вероятность/плотность), а какие менее типичны *с учётом условия* $X=x$. Для каждого фиксированного $x$ это корректное распределение по $y$, то есть оно нормировано:\n",
    "$$\n",
    "\\int_{\\mathcal{Y}} p(y\\mid x),dy = 1\n",
    "\\quad\n",
    "\\text{(или } \\sum_{y\\in\\mathcal{Y}} p(y\\mid x)=1 \\text{ в дискретном случае).}\n",
    "$$\n",
    "\n",
    "Условное `распределение` и совместное связывает следующий закон:\n",
    "$$p(x, y) = p(y \\mid x) p(x) = p(x \\mid y) p(y) \\Rightarrow \\text{тогда для $p(x, y)$ распределения $p(x)$ и $p(y)$ являются маргинальными распределениями}$$\n",
    "\n",
    "Маргинализация `распределения` (или же закон выинтигрирования) позволяет получить из совместного `распределения` `маргинальное`  явным образом:\n",
    "$$p(x) = \\int_\\mathcal{Y} p(x, y) dy \\quad \\quad p(y) = \\int_\\mathcal{X} p(x, y) dx$$\n",
    "\n",
    "> Схематичный пример того, как выглядит бимодальное распределение объектов $x$, где каждая мода соответствует своему $y$ в совместном распределении $(x, y)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2942bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def kde_1d(x, grid, bandwidth=None):\n",
    "    \"\"\"\n",
    "    Simple Gaussian KDE (no SciPy).\n",
    "    x: (n,) samples\n",
    "    grid: (m,) evaluation points\n",
    "    bandwidth: if None -> Silverman's rule of thumb\n",
    "    \"\"\"\n",
    "    x = np.asarray(x, dtype=float).ravel()\n",
    "    n = x.size\n",
    "    if n < 2:\n",
    "        raise ValueError(\"Need at least 2 samples for KDE.\")\n",
    "\n",
    "    if bandwidth is None:\n",
    "        # Silverman's rule: h = 1.06 * std * n^{-1/5}\n",
    "        std = np.std(x, ddof=1)\n",
    "        bandwidth = 1.06 * std * (n ** (-1/5))\n",
    "        bandwidth = max(bandwidth, 1e-6)\n",
    "\n",
    "    u = (grid[:, None] - x[None, :]) / bandwidth\n",
    "    kernel = np.exp(-0.5 * u**2) / np.sqrt(2 * np.pi)\n",
    "    return kernel.mean(axis=1) / bandwidth\n",
    "\n",
    "# --- Synthetic data (replace with your own samples if needed) ---\n",
    "rng = np.random.default_rng(42)\n",
    "n1, n2 = 1200, 1200\n",
    "\n",
    "# class 1: slightly narrower\n",
    "x1 = np.r_[rng.normal(63.2, 2.1, int(0.9 * n1)),\n",
    "           rng.normal(60.2, 1.6, int(0.1 * n1))]\n",
    "\n",
    "# class 2: has a longer right tail\n",
    "x2 = np.r_[rng.normal(68.2, 2.0, int(0.8 * n2)),\n",
    "           rng.normal(73.0, 2.3, int(0.2 * n2))]\n",
    "\n",
    "x_all = np.r_[x1, x2]\n",
    "\n",
    "# --- KDE on a common grid ---\n",
    "xmin = min(x_all.min(), x1.min(), x2.min()) - 3\n",
    "xmax = max(x_all.max(), x1.max(), x2.max()) + 3\n",
    "grid = np.linspace(xmin, xmax, 600)\n",
    "\n",
    "d1 = kde_1d(x1, grid)\n",
    "d2 = kde_1d(x2, grid)\n",
    "d_all = kde_1d(x_all, grid)\n",
    "\n",
    "# --- Plot (matplotlib only) ---\n",
    "fig, ax = plt.subplots(figsize=(10, 6), dpi=150)\n",
    "\n",
    "# Colors similar to the reference figure\n",
    "c1 = \"#ff4d6d\"   # pink/red\n",
    "c2 = \"#4dabf7\"   # blue\n",
    "\n",
    "ax.fill_between(grid, 0, d1, alpha=0.35, color=c1)\n",
    "ax.plot(grid, d1, color=c1, linewidth=1.2, label=r\"$p(x \\mid y=\\mathrm{class}\\ 1)$\")\n",
    "\n",
    "ax.fill_between(grid, 0, d2, alpha=0.35, color=c2)\n",
    "ax.plot(grid, d2, color=c2, linewidth=1.2, label=r\"$p(x \\mid y=\\mathrm{class}\\ 2)$\")\n",
    "\n",
    "ax.plot(grid, d_all, color=\"black\", linestyle=(0, (4, 4)), linewidth=1.2, label=r\"$p(x)$\")\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(bottom=0)\n",
    "\n",
    "ax.legend(loc=\"upper right\", frameon=True, fancybox=False, framealpha=1.0, edgecolor=\"black\")\n",
    "ax.grid(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcf77ee",
   "metadata": {},
   "source": [
    "#### Выборка\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1687e56",
   "metadata": {},
   "source": [
    "\n",
    "Выборка — это набор наблюдений, полученных из одного и того же неизвестного распределения данных в природе. Обычно предполагают, что элементы выборки независимы и одинаково распределены (i.i.d.), и записывают:\n",
    "$$\n",
    "x_1,\\dots,x_n \\sim p^*(x),\n",
    "$$\n",
    "где $p^*(x)$ — истинное (неизвестное) распределение. В задаче с разметкой наблюдают пары:\n",
    "$$\n",
    "(x_1,y_1),\\dots,(x_n,y_n) \\sim p^*(x,y).\n",
    "$$\n",
    "Задача обучения модели состоит в том, чтобы по выборке построить приближение $p_\\theta \\approx p^*$ (или соответствующие условные распределения).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3131fb",
   "metadata": {},
   "source": [
    "#### Моменты случайных величин: матожидание и дисперсия\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb00e9",
   "metadata": {},
   "source": [
    "\n",
    "Помимо самого распределения (массы/плотности), на практике часто удобно описывать случайную величину $X$ через её **моменты** — числовые характеристики, которые компактно суммируют “типичное значение” и “разброс”.\n",
    "\n",
    "**Математическое ожидание (mean)** — это среднее значение $X$ в смысле вероятностного закона:\n",
    "$$\n",
    "\\mathbb{E}[X] = \\int_{\\mathcal{X}} x\\,p(x)\\,dx\n",
    "\\quad \\text{(или } \\mathbb{E}[X]=\\sum_{x\\in\\mathcal{X}} x\\,p(x)\\text{ в дискретном случае).}\n",
    "$$\n",
    "Интуитивно $\\mathbb{E}[X]$ — это “центр массы” распределения.\n",
    "\n",
    "**Дисперсия (variance)** измеряет разброс значений вокруг среднего:\n",
    "$$\n",
    "\\mathrm{Var}(X)=\\mathbb{E}\\!\\left[(X-\\mathbb{E}[X])^2\\right]\n",
    "= \\int_{\\mathcal{X}} (x-\\mu)^2\\,p(x)\\,dx,\\quad \\mu=\\mathbb{E}[X].\n",
    "$$\n",
    "Часто используют также **стандартное отклонение** $\\sigma=\\sqrt{\\mathrm{Var}(X)}$, так как оно имеет те же единицы измерения, что и $X$.\n",
    "\n",
    "Для **векторных** данных $X\\in\\mathbb{R}^d$ аналогами являются средний вектор и ковариационная матрица:\n",
    "$$\n",
    "\\mu=\\mathbb{E}[X]\\in\\mathbb{R}^d,\\qquad\n",
    "\\Sigma=\\mathrm{Cov}(X)=\\mathbb{E}\\!\\left[(X-\\mu)(X-\\mu)^\\top\\right]\\in\\mathbb{R}^{d\\times d}.\n",
    "$$\n",
    "Диагональные элементы $\\Sigma$ — дисперсии отдельных координат, а внедиагональные — их взаимосвязь (корреляция/зависимость).\n",
    "\n",
    "Наконец, если у нас есть выборка $x_1,\\dots,x_n$, то моменты обычно оценивают эмпирически:\n",
    "$$\n",
    "\\hat\\mu=\\frac{1}{n}\\sum_{i=1}^n x_i,\\qquad\n",
    "\\widehat{\\mathrm{Var}}(X)=\\frac{1}{n-1}\\sum_{i=1}^n (x_i-\\hat\\mu)^2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35330620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def normal_pdf(x, mu, sigma):\n",
    "    return (1.0 / (np.sqrt(2*np.pi) * sigma)) * np.exp(-0.5 * ((x - mu) / sigma)**2)\n",
    "\n",
    "# параметры двух распределений: одинаковое матожидание, разная дисперсия\n",
    "mu = 0.0\n",
    "sigma1 = 1.0\n",
    "sigma2 = 2.0\n",
    "\n",
    "x = np.linspace(-8, 8, 800)\n",
    "p1 = normal_pdf(x, mu, sigma1)\n",
    "p2 = normal_pdf(x, mu, sigma2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5), dpi=150)\n",
    "\n",
    "ax.plot(x, p1, label=rf\"$p_1(x)$: $\\mathbb{{E}}[X]={mu}$, $\\mathrm{{Var}}(X)={sigma1**2}$\")\n",
    "ax.plot(x, p2, label=rf\"$p_2(x)$: $\\mathbb{{E}}[X]={mu}$, $\\mathrm{{Var}}(X)={sigma2**2}$\")\n",
    "\n",
    "# матожидание\n",
    "ax.axvline(mu, linewidth=1.6, label=rf\"$\\mu=\\mathbb{{E}}[X]$\")\n",
    "\n",
    "# интервалы +-1 sigma (для каждого распределения своим штрихом)\n",
    "ax.axvline(mu - sigma1, linestyle=\"--\", linewidth=1.2, label=rf\"$\\mu\\pm\\sigma_1$ (narrow)\")\n",
    "ax.axvline(mu + sigma1, linestyle=\"--\", linewidth=1.2)\n",
    "\n",
    "ax.axvline(mu - sigma2, linestyle=\":\", linewidth=1.4, label=rf\"$\\mu\\pm\\sigma_2$ (wide)\")\n",
    "ax.axvline(mu + sigma2, linestyle=\":\", linewidth=1.4)\n",
    "\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"Density\")\n",
    "ax.set_title(r\"Mean $\\mathbb{E}[X]$ and spread via standard deviation $\\sigma=\\sqrt{\\mathrm{Var}(X)}$\")\n",
    "ax.set_ylim(bottom=0)\n",
    "ax.legend(loc=\"upper right\", frameon=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dacfed3",
   "metadata": {},
   "source": [
    "## Дискриминативный vs. Генеративный ИИ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445aeb77",
   "metadata": {},
   "source": [
    "В вероятностном ML есть два **принципиально разных** режима работы с данными: `дискриминативный` и `генеративный`. Важно сразу зафиксировать: это **не** «классификация vs генерация изображений/текстов/графов (нужное подчеркнуть)». Классификация — лишь частный случай дискриминативного инференса, а генеративные модели часто решают *и* классификацию, и восстановление пропусков, и построение симуляторов — то есть работают как более общий инструмент моделирования данных.\n",
    "\n",
    "Далее (как и выше) будем считать:\n",
    "- $x\\in\\mathcal{X}$ — наблюдаемые признаки объекта (регрессоры),\n",
    "- $y\\in\\mathcal{Y}$ — скрытая/целевая характеристика (класс, число, метка, атрибут, условие)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b619a0e5",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"images/lecture_1/discriminative_generative.png\" style=\"width:60%;\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9980dbbd",
   "metadata": {},
   "source": [
    "#### Конструктивное сравнение двух подходов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6175248c",
   "metadata": {},
   "source": [
    "\n",
    "**`Дискриминативная задача`** формулируется как моделирование условного распределения\n",
    "$\n",
    "p_\\theta(y\\mid x) \\Rightarrow\n",
    "$\n",
    "мы выучиваем «как распределён $y$, если $x$ зафиксирован». И на инференсе $x$ обязателен: без наблюдения признаков условное распределение просто не информативно для решения данной задачи.\n",
    "\n",
    "Здесь важно различать два уровня:\n",
    "1) **вероятностный выход** модели: она возвращает распределение/его параметры (например, вектор вероятностей классов, параметры гауссианы и т.п.);\n",
    "2) **предсказание** как детерминированное решение на основе распределения, например\n",
    "$$\n",
    "\\hat y(x)=\\arg\\max_{y\\in\\mathcal{Y}} p_\\theta(y\\mid x)\\quad\\text{(MAP-оценка)}, \\quad \\text{или} \\quad \\hat y(x)=\\mathbb{E}_\\theta[y\\mid x]\\quad\\text{(регрессия/байесовская точечная оценка).}\n",
    "$$\n",
    "\n",
    "\n",
    "> То есть дискриминативная модель по сути отвечает на вопрос: *«что можно утверждать про объект, если мы его уже наблюдаем?»*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d798e2",
   "metadata": {},
   "source": [
    "\n",
    "**`Генеративная задача`** ориентирована на моделирование распределения самих наблюдаемых данных. В зависимости от контекста моделируют:\n",
    "- безусловное $p_\\theta(x)$,\n",
    "- совместное $p_\\theta(x,y)$,\n",
    "- или условное $p_\\theta(x\\mid y)$ (контролируемая генерация).\n",
    "\n",
    "Ключевым критерием выступает умение модели **семплировать**/создавать новые наблюдения,\n",
    "$$\n",
    "x\\sim p_\\theta(x) \\qquad\\text{или}\\qquad x \\mid y \\sim p_\\theta(x\\mid y),\n",
    "$$\n",
    "такие, что они статистически согласованы с истинным распределением данных. Модель должна уметь **воспроизводить структуру множества объектов** и порождать новые экземпляры этой структуры. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcfc256",
   "metadata": {},
   "source": [
    "#### Связь подходов. Теорема Байеса\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44504e3",
   "metadata": {},
   "source": [
    "Ключевая связь между двумя парадигмами возникает, когда мы моделируем **совместный закон `распределения`** $p_\\theta(x,y)$. Тогда дискриминативное распределение получается как *производное* по формуле Байеса:\n",
    "$$\n",
    "p_\\theta(y\\mid x) \\;=\\; \\frac{p_\\theta(x, y)}{p_\\theta(x)} = \\frac{p_\\theta(x\\mid y)\\,p_\\theta(y)}{p_\\theta(x)},\n",
    "\\qquad\n",
    "p_\\theta(x)=\\underbrace{\\sum_{y\\in\\mathcal{Y}} p_\\theta(x\\mid y)\\,p_\\theta(y)}_{\\text{(дискретный \\(y\\))}} = \\underbrace{\\int p_\\theta(x\\mid y)\\,p_\\theta(y)\\,dy}_\\text{(непрерывный \\(y\\))}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4886d7",
   "metadata": {},
   "source": [
    "#### Сравнение обучения моделей двух подходов\n",
    "\n",
    "В дискриминативном обучении (при разметке) естественная цель — максимизация *условного* лог-правдоподобия:\n",
    "$$\n",
    "\\hat\\theta=\\arg\\max_\\theta \\sum_{i=1}^n \\log p_\\theta(y_i\\mid x_i),\n",
    "$$\n",
    "что в классификации эквивалентно минимизации кросс-энтропии (или логистический лосс в случае бинарной классификации), а в регрессии — взятию функции правдоподобия под выбранную модель шума (гауссовский $\\Rightarrow$ MSE, лапласовский $\\Rightarrow$ MAE и т.д.).\n",
    "\n",
    "В генеративном обучении мы исходим из гипотезы, что данные порождены некоторым неизвестным распределением $p^*(x)$, и хотим построить параметрическое приближение $p_\\theta(x)$, которое (в пределе бесконечных данных) согласуется с $p^*$ настолько, насколько это возможно в выбранном семействе моделей.\n",
    "\n",
    "Пусть $x_1,\\dots,x_n \\stackrel{i.i.d.}{\\sim} p^*(x)$. Конструктивная цель — максимизировать правдоподобие наблюдаемой выборки:\n",
    "$$\n",
    "\\hat\\theta_n=\\arg\\max_{\\theta\\in\\Theta}\\sum_{i=1}^n \\log p_\\theta(x_i)\n",
    "\\quad\\Longleftrightarrow\\quad\n",
    "\\arg\\min_{\\theta\\in\\Theta}\\; \\hat L_n(\\theta) = -\\frac1n\\sum_{i=1}^n \\log p_\\theta(x_i).\n",
    "$$\n",
    "\n",
    "При $n\\to\\infty$ по закону больших чисел $\\hat L_n(\\theta)\\to L(\\theta)$, где\n",
    "$$\n",
    "L(\\theta)=\\mathbb{E}_{x\\sim p^*}\\big[-\\log p_\\theta(x)\\big].\n",
    "$$\n",
    "\n",
    "Далее получаем стандартное разложение:\n",
    "$$\n",
    "\\begin{align*}\n",
    "L(\\theta)\n",
    "&=\\mathbb{E}_{p^*}\\big[-\\log p_\\theta(x)\\big] \\\\\n",
    "&=\\mathbb{E}_{p^*}\\big[-\\log p^*(x)\\big] + \\mathbb{E}_{p^*}\\Big[\\log \\frac{p^*(x)}{p_\\theta(x)}\\Big] \\\\\n",
    "&=\\int_{\\mathcal{X}} p^*(x)\\,\\big[-\\log p^*(x)\\big]\\,dx \\;+\\; \\int_{\\mathcal{X}} p^*(x)\\,\\log\\!\\frac{p^*(x)}{p_\\theta(x)}\\,dx \\\\\n",
    "&=H(p^*)+\\mathrm{KL}\\!\\left(p^*\\|p_\\theta\\right).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Поскольку $H(p^*)$ не зависит от $\\theta$, минимизация $L(\\theta)$ эквивалентна минимизации $\\mathrm{KL}(p^*\\|p_\\theta)$. Значит, максимизируя $\\sum_{i=1}^n \\log p_\\theta(x_i)$, мы подгоняем выучиваемое распределение $p_\\theta$ под истинное $p^*$ в KL-смысле — ровно то, что и является целью генеративного обучения.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb2d528",
   "metadata": {},
   "source": [
    "### Визуализация обучения Дискриминативного и Генеративного ИИ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0ec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Discriminative: Logistic regression via gradient descent (parameter path)\n",
    "# -----------------------------\n",
    "import numpy as np\n",
    "\n",
    "def logistic_regression_gd_path(\n",
    "    X1, X2,\n",
    "    lr=0.1, n_iters=200, l2=0.0, fit_intercept=True, seed=0,\n",
    "    lr_mode=\"constant\",            # <-- NEW: \"constant\" or \"warmup\"\n",
    "    warmup_power=2.0,              # <-- NEW: controls how slow the start is\n",
    "    lr_max=None                    # <-- NEW: if None, estimated automatically\n",
    "):\n",
    "    X1 = np.asarray(X1, dtype=float)\n",
    "    X2 = np.asarray(X2, dtype=float)\n",
    "    if X1.ndim != 2 or X2.ndim != 2:\n",
    "        raise ValueError(\"X1 and X2 must be 2D arrays of shape (n, d).\")\n",
    "    if X1.shape[1] != X2.shape[1]:\n",
    "        raise ValueError(\"X1 and X2 must have the same feature dimension d.\")\n",
    "\n",
    "    X = np.vstack([X1, X2])\n",
    "    y = np.concatenate([np.zeros(len(X1)), np.ones(len(X2))])\n",
    "\n",
    "    n, d = X.shape\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    w = 0.01 * rng.standard_normal(d)\n",
    "    b = 0.0\n",
    "\n",
    "    def sigmoid(z):\n",
    "        z = np.clip(z, -50.0, 50.0)\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def nll(w, b):\n",
    "        z = X @ w + (b if fit_intercept else 0.0)\n",
    "        p = sigmoid(z)\n",
    "        eps = 1e-12\n",
    "        loss = -np.mean(y * np.log(p + eps) + (1 - y) * np.log(1 - p + eps))\n",
    "        if l2 > 0:\n",
    "            loss += 0.5 * l2 * np.sum(w * w)\n",
    "        return loss\n",
    "\n",
    "    # ---- NEW: choose lr_max automatically if warmup requested ----\n",
    "    if lr_mode == \"warmup\" and lr_max is None:\n",
    "        # Lipschitz upper bound using Frobenius norm\n",
    "        fro2 = np.sum(X * X)  # ||X||_F^2\n",
    "        L = 0.25 * (fro2 / n) + l2\n",
    "        lr_max = 0.9 / (L + 1e-12)\n",
    "\n",
    "    w_path = np.zeros((n_iters + 1, d))\n",
    "    b_path = np.zeros(n_iters + 1)\n",
    "    loss_path = np.zeros(n_iters + 1)\n",
    "\n",
    "    w_path[0] = w\n",
    "    b_path[0] = b\n",
    "    loss_path[0] = nll(w, b)\n",
    "\n",
    "    for t in range(1, n_iters + 1):\n",
    "        z = X @ w + (b if fit_intercept else 0.0)\n",
    "        p = sigmoid(z)\n",
    "\n",
    "        grad_w = (X.T @ (p - y)) / n\n",
    "        if l2 > 0:\n",
    "            grad_w += l2 * w\n",
    "\n",
    "        grad_b = np.mean(p - y) if fit_intercept else 0.0\n",
    "\n",
    "        # ---- NEW: step size schedule ----\n",
    "        if lr_mode == \"constant\":\n",
    "            step = lr\n",
    "        elif lr_mode == \"warmup\":\n",
    "            # step grows from ~0 to lr_max, making learning visibly gradual\n",
    "            frac = (t / n_iters) ** warmup_power\n",
    "            step = float(lr_max) * frac\n",
    "        else:\n",
    "            raise ValueError(\"lr_mode must be 'constant' or 'warmup'.\")\n",
    "\n",
    "        w -= step * grad_w\n",
    "        if fit_intercept:\n",
    "            b -= step * grad_b\n",
    "\n",
    "        w_path[t] = w\n",
    "        b_path[t] = b\n",
    "        loss_path[t] = nll(w, b)\n",
    "\n",
    "    return w_path, b_path, loss_path\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Generative: 2-Gaussian Mixture via EM + sampling\n",
    "# -----------------------------\n",
    "def sample_from_gmm(pi, mu, Sigma, n_samples=200, seed=0):\n",
    "    \"\"\"\n",
    "    Sample points from a 2-component Gaussian mixture.\n",
    "    Returns samples (n_samples,d) and component labels z (n_samples,).\n",
    "    \"\"\"\n",
    "    pi = np.asarray(pi, float)\n",
    "    mu = np.asarray(mu, float)\n",
    "    Sigma = np.asarray(Sigma, float)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    z = rng.choice(2, size=n_samples, p=pi)\n",
    "\n",
    "    d = mu.shape[1]\n",
    "    samples = np.zeros((n_samples, d), float)\n",
    "    for k in range(2):\n",
    "        idx = np.where(z == k)[0]\n",
    "        if len(idx) == 0:\n",
    "            continue\n",
    "        samples[idx] = rng.multivariate_normal(mean=mu[k], cov=Sigma[k], size=len(idx))\n",
    "    return samples, z\n",
    "\n",
    "\n",
    "def gmm2_em_and_sample(X1, X2, n_iters=100, tol=1e-6, reg_covar=1e-6, n_samples=200, seed=0):\n",
    "    \"\"\"\n",
    "    Fit a 2-component Gaussian Mixture Model using EM on the union of X1 and X2.\n",
    "    Uses X1 and X2 only for *initialization* (means/covariances/mixture weights).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X1, X2 : array-like\n",
    "        Two sets of points, shapes (n1, d), (n2, d).\n",
    "    n_iters : int\n",
    "        Max EM iterations.\n",
    "    tol : float\n",
    "        Convergence tolerance on log-likelihood improvement.\n",
    "    reg_covar : float\n",
    "        Diagonal regularizer added to covariances for numerical stability.\n",
    "    n_samples : int\n",
    "        Number of points to sample from the learned mixture.\n",
    "    seed : int\n",
    "        Random seed.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    params : dict\n",
    "        {\n",
    "          \"pi\": (2,),\n",
    "          \"mu\": (2, d),\n",
    "          \"Sigma\": (2, d, d),\n",
    "          \"loglik_path\": (T,)   # T <= n_iters\n",
    "        }\n",
    "    samples : np.ndarray\n",
    "        Shape (n_samples, d), sampled from the learned mixture.\n",
    "    responsibilities : np.ndarray\n",
    "        Shape (n, 2), final responsibilities r_{ik}.\n",
    "    \"\"\"\n",
    "    X1 = np.asarray(X1, dtype=float)\n",
    "    X2 = np.asarray(X2, dtype=float)\n",
    "    if X1.ndim != 2 or X2.ndim != 2:\n",
    "        raise ValueError(\"X1 and X2 must be 2D arrays of shape (n, d).\")\n",
    "    if X1.shape[1] != X2.shape[1]:\n",
    "        raise ValueError(\"X1 and X2 must have the same feature dimension d.\")\n",
    "\n",
    "    X = np.vstack([X1, X2])\n",
    "    n, d = X.shape\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # ----- Initialization (using the two sets) -----\n",
    "    mu = np.stack([X1.mean(axis=0), X2.mean(axis=0)], axis=0)  # (2, d)\n",
    "    def empirical_cov(A):\n",
    "        A = np.asarray(A, float)\n",
    "        if len(A) <= 1:\n",
    "            return np.eye(d)\n",
    "        C = np.cov(A.T, bias=False)\n",
    "        if C.ndim == 0:  # d=1 edge case\n",
    "            C = np.array([[float(C)]])\n",
    "        return C\n",
    "\n",
    "    Sigma = np.stack([empirical_cov(X1), empirical_cov(X2)], axis=0)  # (2, d, d)\n",
    "    Sigma += reg_covar * np.eye(d)[None, :, :]\n",
    "\n",
    "    pi = np.array([len(X1), len(X2)], dtype=float)\n",
    "    pi = pi / pi.sum()\n",
    "\n",
    "    # Helpers\n",
    "    def log_gaussian_pdf(X, m, S):\n",
    "        \"\"\"\n",
    "        log N(x | m, S) for each row in X. Returns shape (n,)\n",
    "        \"\"\"\n",
    "        # Cholesky for stability\n",
    "        L = np.linalg.cholesky(S)\n",
    "        # Solve (x-m) in whitened coordinates: v = L^{-1} (x-m)\n",
    "        Xm = X - m\n",
    "        v = np.linalg.solve(L, Xm.T)  # (d, n)\n",
    "        quad = np.sum(v * v, axis=0)  # (n,)\n",
    "        log_det = 2.0 * np.sum(np.log(np.diag(L)))\n",
    "        return -0.5 * (d * np.log(2.0 * np.pi) + log_det + quad)\n",
    "\n",
    "    def logsumexp(a, axis=1):\n",
    "        amax = np.max(a, axis=axis, keepdims=True)\n",
    "        return (amax + np.log(np.sum(np.exp(a - amax), axis=axis, keepdims=True))).squeeze(axis)\n",
    "\n",
    "    loglik_path = []\n",
    "    prev_ll = -np.inf\n",
    "\n",
    "    for it in range(n_iters):\n",
    "        # ----- E-step -----\n",
    "        # log r_ik proportional to log pi_k + log N(x_i | mu_k, Sigma_k)\n",
    "        log_r = np.zeros((n, 2))\n",
    "        for k in range(2):\n",
    "            log_r[:, k] = np.log(pi[k] + 1e-16) + log_gaussian_pdf(X, mu[k], Sigma[k])\n",
    "\n",
    "        ll = np.sum(logsumexp(log_r, axis=1))\n",
    "        loglik_path.append(ll)\n",
    "\n",
    "        # Normalize responsibilities\n",
    "        log_norm = logsumexp(log_r, axis=1)  # (n,)\n",
    "        r = np.exp(log_r - log_norm[:, None])  # (n,2)\n",
    "\n",
    "        # Convergence check\n",
    "        if it > 0 and abs(ll - prev_ll) < tol * (1.0 + abs(prev_ll)):\n",
    "            break\n",
    "        prev_ll = ll\n",
    "\n",
    "        # ----- M-step -----\n",
    "        Nk = r.sum(axis=0) + 1e-16  # (2,)\n",
    "        pi = Nk / n\n",
    "\n",
    "        # Update means\n",
    "        mu = (r.T @ X) / Nk[:, None]  # (2,d)\n",
    "\n",
    "        # Update covariances\n",
    "        Sigma_new = np.zeros((2, d, d))\n",
    "        for k in range(2):\n",
    "            Xm = X - mu[k]  # (n,d)\n",
    "            # Weighted covariance: sum_i r_ik (x_i-mu)(x_i-mu)^T / Nk\n",
    "            Sigma_new[k] = (Xm.T * r[:, k]) @ Xm / Nk[k]\n",
    "            Sigma_new[k] += reg_covar * np.eye(d)\n",
    "        Sigma = Sigma_new\n",
    "\n",
    "    # ----- Sampling from the learned mixture -----\n",
    "    # Choose component indices\n",
    "    z = rng.choice(2, size=n_samples, p=pi)\n",
    "    samples = np.zeros((n_samples, d))\n",
    "    for k in range(2):\n",
    "        idx = np.where(z == k)[0]\n",
    "        if len(idx) == 0:\n",
    "            continue\n",
    "        samples[idx] = rng.multivariate_normal(mean=mu[k], cov=Sigma[k], size=len(idx))\n",
    "\n",
    "    params = {\n",
    "        \"pi\": pi,\n",
    "        \"mu\": mu,\n",
    "        \"Sigma\": Sigma,\n",
    "        \"loglik_path\": np.array(loglik_path, dtype=float),\n",
    "    }\n",
    "    return params, samples, r\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Optional: convenience (2D line from hyperplane)\n",
    "# -----------------------------\n",
    "def line_from_hyperplane_2d(w, b, x_min, x_max, n=200):\n",
    "    \"\"\"\n",
    "    For d=2, returns points on the decision boundary w^T x + b = 0:\n",
    "    y = -(w0/w1) x - b/w1\n",
    "    \"\"\"\n",
    "    w = np.asarray(w, dtype=float)\n",
    "    if w.shape[0] != 2:\n",
    "        raise ValueError(\"This helper is only for 2D (w must have shape (2,)).\")\n",
    "    xs = np.linspace(x_min, x_max, n)\n",
    "    if abs(w[1]) < 1e-12:\n",
    "        # vertical line: w0 x + b = 0 -> x = -b/w0\n",
    "        x0 = -b / (w[0] + 1e-12)\n",
    "        ys = np.linspace(-1.0, 1.0, n)\n",
    "        xs = np.full_like(ys, x0)\n",
    "    else:\n",
    "        ys = -(w[0] * xs + b) / w[1]\n",
    "    return xs, ys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246fb7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Helpers: robustly unpack outputs\n",
    "# -----------------------------\n",
    "def _as_logreg_bundle(logreg_out):\n",
    "    \"\"\"\n",
    "    Accept either:\n",
    "      - dict with keys: X1, X2, w_path, b_path (loss_path optional)\n",
    "      - tuple: (w_path, b_path, loss_path, X1, X2) or (w_path, b_path, loss_path) + pass X1,X2 separately (not supported here)\n",
    "    \"\"\"\n",
    "    if isinstance(logreg_out, dict):\n",
    "        required = [\"X1\", \"X2\", \"w_path\", \"b_path\"]\n",
    "        for k in required:\n",
    "            if k not in logreg_out:\n",
    "                raise ValueError(f\"logreg_out dict must contain key '{k}'.\")\n",
    "        X1 = np.asarray(logreg_out[\"X1\"], float)\n",
    "        X2 = np.asarray(logreg_out[\"X2\"], float)\n",
    "        w_path = np.asarray(logreg_out[\"w_path\"], float)\n",
    "        b_path = np.asarray(logreg_out[\"b_path\"], float)\n",
    "        loss_path = np.asarray(logreg_out.get(\"loss_path\", []), float)\n",
    "        return X1, X2, w_path, b_path, loss_path\n",
    "\n",
    "    if isinstance(logreg_out, (tuple, list)) and len(logreg_out) >= 5:\n",
    "        w_path, b_path, loss_path, X1, X2 = logreg_out[:5]\n",
    "        return np.asarray(X1, float), np.asarray(X2, float), np.asarray(w_path, float), np.asarray(b_path, float), np.asarray(loss_path, float)\n",
    "\n",
    "    raise ValueError(\"Unsupported logreg_out format. Use dict or tuple (w_path,b_path,loss_path,X1,X2).\")\n",
    "\n",
    "\n",
    "def _as_gmm_bundle(gmm_out):\n",
    "    \"\"\"\n",
    "    Accept either:\n",
    "      - dict with keys: X1, X2, params, samples (responsibilities optional)\n",
    "      - tuple: (params, samples, responsibilities, X1, X2) or (params, samples, responsibilities) + pass X1,X2 separately (not supported here)\n",
    "    \"\"\"\n",
    "    if isinstance(gmm_out, dict):\n",
    "        required = [\"X1\", \"X2\", \"params\", \"samples\"]\n",
    "        for k in required:\n",
    "            if k not in gmm_out:\n",
    "                raise ValueError(f\"gmm_out dict must contain key '{k}'.\")\n",
    "        X1 = np.asarray(gmm_out[\"X1\"], float)\n",
    "        X2 = np.asarray(gmm_out[\"X2\"], float)\n",
    "        params = gmm_out[\"params\"]\n",
    "        samples = np.asarray(gmm_out[\"samples\"], float)\n",
    "        r = gmm_out.get(\"responsibilities\", None)\n",
    "        if r is not None:\n",
    "            r = np.asarray(r, float)\n",
    "        return X1, X2, params, samples, r\n",
    "\n",
    "    if isinstance(gmm_out, (tuple, list)) and len(gmm_out) >= 5:\n",
    "        params, samples, r, X1, X2 = gmm_out[:5]\n",
    "        return np.asarray(X1, float), np.asarray(X2, float), params, np.asarray(samples, float), (None if r is None else np.asarray(r, float))\n",
    "\n",
    "    raise ValueError(\"Unsupported gmm_out format. Use dict or tuple (params,samples,r,X1,X2).\")\n",
    "\n",
    "\n",
    "def _clamp_index(t, T):\n",
    "    if T <= 0:\n",
    "        return 0\n",
    "    return int(max(0, min(int(t), T - 1)))\n",
    "\n",
    "\n",
    "def _cov_ellipse_points(mu, Sigma, n=200, nsig=2.0):\n",
    "    \"\"\"\n",
    "    Return x,y points of an ellipse corresponding to nsig standard deviations\n",
    "    for a 2D Gaussian N(mu, Sigma).\n",
    "    \"\"\"\n",
    "    mu = np.asarray(mu, float).reshape(2,)\n",
    "    Sigma = np.asarray(Sigma, float).reshape(2, 2)\n",
    "\n",
    "    # Eigen-decomposition\n",
    "    vals, vecs = np.linalg.eigh(Sigma)\n",
    "    vals = np.maximum(vals, 1e-15)\n",
    "\n",
    "    # Parametric circle\n",
    "    theta = np.linspace(0, 2*np.pi, n)\n",
    "    circle = np.stack([np.cos(theta), np.sin(theta)], axis=0)  # (2, n)\n",
    "\n",
    "    # Scale circle to ellipse: vecs @ diag(sqrt(vals)) @ circle\n",
    "    A = vecs @ (np.diag(np.sqrt(vals)) * nsig)\n",
    "    ell = (A @ circle).T + mu[None, :]  # (n,2)\n",
    "    return ell[:, 0], ell[:, 1]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Plot: Logistic regression boundary at timestamp t\n",
    "# -----------------------------\n",
    "def plot_logreg_snapshot(logreg_out, t, ax=None, dims=(0, 1), padding=0.08, title=True):\n",
    "    \"\"\"\n",
    "    Plot a snapshot of logistic regression decision boundary at iteration t.\n",
    "    Expects d>=2 for visualization; uses dims=(i,j) projection.\n",
    "\n",
    "    logreg_out: dict with X1, X2, w_path, b_path (loss_path optional), or tuple.\n",
    "    \"\"\"\n",
    "    X1, X2, w_path, b_path, loss_path = _as_logreg_bundle(logreg_out)\n",
    "\n",
    "    if X1.shape[1] < 2:\n",
    "        raise ValueError(\"Need at least 2D points for a 2D boundary plot.\")\n",
    "    i, j = dims\n",
    "\n",
    "    T = w_path.shape[0]\n",
    "    t = _clamp_index(t, T)\n",
    "    w = w_path[t]\n",
    "    b = float(b_path[t])\n",
    "\n",
    "    # Project data and weights\n",
    "    X1p = X1[:, [i, j]]\n",
    "    X2p = X2[:, [i, j]]\n",
    "    wp = np.asarray([w[i], w[j]], float)\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "\n",
    "    ax.scatter(X1p[:, 0], X1p[:, 1], s=18, label=\"X1 (y=0)\")\n",
    "    ax.scatter(X2p[:, 0], X2p[:, 1], s=18, label=\"X2 (y=1)\")\n",
    "\n",
    "    # Compute plot bounds\n",
    "    Xall = np.vstack([X1p, X2p])\n",
    "    xmin, ymin = Xall.min(axis=0)\n",
    "    xmax, ymax = Xall.max(axis=0)\n",
    "    dx, dy = xmax - xmin, ymax - ymin\n",
    "    xmin -= padding * (dx + 1e-12)\n",
    "    xmax += padding * (dx + 1e-12)\n",
    "    ymin -= padding * (dy + 1e-12)\n",
    "    ymax += padding * (dy + 1e-12)\n",
    "\n",
    "    # Decision boundary: wp[0]*x + wp[1]*y + b = 0\n",
    "    xs = np.linspace(xmin, xmax, 200)\n",
    "    if abs(wp[1]) < 1e-12:\n",
    "        # vertical line\n",
    "        x0 = -b / (wp[0] + 1e-12)\n",
    "        ax.plot([x0, x0], [ymin, ymax], linewidth=2)\n",
    "    else:\n",
    "        ys = -(wp[0] * xs + b) / wp[1]\n",
    "        ax.plot(xs, ys, linewidth=2)\n",
    "\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.set_xlabel(f\"x[{i}]\")\n",
    "    ax.set_ylabel(f\"x[{j}]\")\n",
    "\n",
    "    if title:\n",
    "        if loss_path.size == 0:\n",
    "            ax.set_title(f\"Logistic regression boundary\")\n",
    "        else:\n",
    "            # loss_path might be length T, but be robust\n",
    "            lt = loss_path[t] if t < len(loss_path) else np.nan\n",
    "            ax.set_title(f\"Logistic regression boundary\")\n",
    "\n",
    "    ax.legend(frameon=False)\n",
    "    ax.grid(True, linewidth=0.5)\n",
    "    return ax\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Plot: GMM snapshot at timestamp t\n",
    "# -----------------------------\n",
    "def plot_gmm_snapshot(\n",
    "    gmm_out, t, ax=None, dims=(0, 1), padding=0.08, title=True,\n",
    "    show_samples=True, ellipse_nsig=(1.0, 2.0),\n",
    "    n_samples=250, sample_seed=0, color_samples=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot a 2-component GMM snapshot.\n",
    "    FIX: samples are generated from the parameters at the selected timestamp t.\n",
    "\n",
    "    If params has history: use params at iter t.\n",
    "    Otherwise: use final params.\n",
    "    \"\"\"\n",
    "    X1, X2, params, _samples_unused, r = _as_gmm_bundle(gmm_out)\n",
    "\n",
    "    if X1.shape[1] < 2:\n",
    "        raise ValueError(\"Need at least 2D points for a 2D GMM plot.\")\n",
    "    i, j = dims\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "\n",
    "    # --- Scatter data and capture their colors ---\n",
    "    X1p = X1[:, [i, j]]\n",
    "    X2p = X2[:, [i, j]]\n",
    "    sc1 = ax.scatter(X1p[:, 0], X1p[:, 1], s=18, label=\"X1\")\n",
    "    sc2 = ax.scatter(X2p[:, 0], X2p[:, 1], s=18, label=\"X2\")\n",
    "\n",
    "    def _pick_color(sc):\n",
    "        fc = sc.get_facecolor()\n",
    "        if fc is not None and len(fc) > 0:\n",
    "            return fc[0]\n",
    "        ec = sc.get_edgecolor()\n",
    "        if ec is not None and len(ec) > 0:\n",
    "            return ec[0]\n",
    "        return None\n",
    "\n",
    "    col_X1 = _pick_color(sc1)\n",
    "    col_X2 = _pick_color(sc2)\n",
    "\n",
    "    # --- Choose which parameters to plot ---\n",
    "    if \"history\" in params and params[\"history\"] is not None:\n",
    "        hist = params[\"history\"]\n",
    "        pi_path = np.asarray(hist[\"pi_path\"], float)\n",
    "        mu_path = np.asarray(hist[\"mu_path\"], float)\n",
    "        Sig_path = np.asarray(hist[\"Sigma_path\"], float)\n",
    "        T = pi_path.shape[0]\n",
    "        tt = _clamp_index(t, T)\n",
    "        pi = pi_path[tt]\n",
    "        mu = mu_path[tt]\n",
    "        Sigma = Sig_path[tt]\n",
    "        used_t = tt\n",
    "    else:\n",
    "        pi = np.asarray(params[\"pi\"], float)\n",
    "        mu = np.asarray(params[\"mu\"], float)\n",
    "        Sigma = np.asarray(params[\"Sigma\"], float)\n",
    "        used_t = None\n",
    "        tt = 0  # for deterministic seed below\n",
    "\n",
    "    # --- Stabilize component<->dataset color mapping by mean proximity ---\n",
    "    m1 = X1.mean(axis=0)\n",
    "    m2 = X2.mean(axis=0)\n",
    "    c_01 = np.linalg.norm(mu[0] - m1) + np.linalg.norm(mu[1] - m2)\n",
    "    c_10 = np.linalg.norm(mu[0] - m2) + np.linalg.norm(mu[1] - m1)\n",
    "    if c_01 <= c_10:\n",
    "        comp_color = [col_X1, col_X2]\n",
    "    else:\n",
    "        comp_color = [col_X2, col_X1]\n",
    "\n",
    "    # --- Plot means and ellipses with fixed colors ---\n",
    "    for k in range(2):\n",
    "        color = comp_color[k]\n",
    "        muk = mu[k, [i, j]]\n",
    "        Sigk = Sigma[k][np.ix_([i, j], [i, j])]\n",
    "\n",
    "        ax.scatter([muk[0]], [muk[1]], s=60, marker=\"x\", linewidths=2, color='black')\n",
    "\n",
    "        for ns in ellipse_nsig:\n",
    "            ex, ey = _cov_ellipse_points(muk, Sigk, nsig=float(ns))\n",
    "            ax.plot(ex, ey, linewidth=1.5, color=color)\n",
    "\n",
    "    # --- FIX: sample from CURRENT (pi,mu,Sigma) at timestamp t ---\n",
    "    if show_samples and n_samples > 0:\n",
    "        # deterministic per-timestamp seed so samples don't jump around\n",
    "        seed_t = int(sample_seed) + 10_000 * int(tt)\n",
    "        samples_t, z_t = sample_from_gmm(pi, mu, Sigma, n_samples=n_samples, seed=seed_t)\n",
    "        sp = samples_t[:, [i, j]]\n",
    "\n",
    "        if color_samples:\n",
    "            # color samples by component, using the same fixed colors as ellipses\n",
    "            for k in range(2):\n",
    "                idx = np.where(z_t == k)[0]\n",
    "                if len(idx) == 0:\n",
    "                    continue\n",
    "                ax.scatter(sp[idx, 0], sp[idx, 1], s=10, marker=\".\", color=comp_color[k], alpha=0.8)\n",
    "        else:\n",
    "            ax.scatter(sp[:, 0], sp[:, 1], s=10, marker=\".\", label=\"samples\")\n",
    "\n",
    "    # --- Bounds ---\n",
    "    Xall = np.vstack([X1p, X2p])\n",
    "    xmin, ymin = Xall.min(axis=0)\n",
    "    xmax, ymax = Xall.max(axis=0)\n",
    "    dx, dy = xmax - xmin, ymax - ymin\n",
    "    xmin -= padding * (dx + 1e-12)\n",
    "    xmax += padding * (dx + 1e-12)\n",
    "    ymin -= padding * (dy + 1e-12)\n",
    "    ymax += padding * (dy + 1e-12)\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "\n",
    "    ax.set_xlabel(f\"x[{i}]\")\n",
    "    ax.set_ylabel(f\"x[{j}]\")\n",
    "    ax.grid(True, linewidth=0.5)\n",
    "\n",
    "    if title:\n",
    "        ax.set_title(\"2-GMM (EM) snapshot\")\n",
    "\n",
    "    ax.legend(frameon=False)\n",
    "    return ax\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Plot both paradigms in one row\n",
    "# -----------------------------\n",
    "def plot_two_paradigms_row(logreg_out, gmm_out, t, dims=(0, 1), figsize=(12, 5), share_limits=False):\n",
    "    \"\"\"\n",
    "    Draw two plots in a single row:\n",
    "      - Left: discriminative logistic regression boundary @ t\n",
    "      - Right: generative GMM fit @ t (or final if history absent)\n",
    "\n",
    "    If share_limits=True, both axes use the same x/y limits (based on combined data).\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=figsize)\n",
    "\n",
    "    ax0 = plot_logreg_snapshot(logreg_out, t=t, ax=axes[0], dims=dims, title=True)\n",
    "    ax1 = plot_gmm_snapshot(gmm_out, t=t, ax=axes[1], dims=dims, title=True)\n",
    "\n",
    "    if share_limits:\n",
    "        # Compute combined limits\n",
    "        X1, X2, _, _, _ = _as_logreg_bundle(logreg_out)\n",
    "        Xall = np.vstack([X1[:, list(dims)], X2[:, list(dims)]])\n",
    "        xmin, ymin = Xall.min(axis=0)\n",
    "        xmax, ymax = Xall.max(axis=0)\n",
    "        dx, dy = xmax - xmin, ymax - ymin\n",
    "        pad = 0.08\n",
    "        xmin -= pad * (dx + 1e-12); xmax += pad * (dx + 1e-12)\n",
    "        ymin -= pad * (dy + 1e-12); ymax += pad * (dy + 1e-12)\n",
    "        ax0.set_xlim(xmin, xmax); ax0.set_ylim(ymin, ymax)\n",
    "        ax1.set_xlim(xmin, xmax); ax1.set_ylim(ymin, ymax)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig, axes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d493c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset generator (as requested)\n",
    "# -----------------------------\n",
    "def create_dataset(n1=200, n2=200, d=2, separation=2.5, cov_scale=0.8, rotate_deg=25.0, seed=0):\n",
    "    \"\"\"\n",
    "    Generate two point clouds X1 and X2 in R^d (default d=2) with controllable overlap.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X1 : (n1, d)\n",
    "    X2 : (n2, d)\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    if d != 2:\n",
    "        # For simplicity of visualization, we stick to d=2 by default.\n",
    "        # You can generalize means/covariances for any d if needed.\n",
    "        raise ValueError(\"This create_dataset is set for d=2 to support 2D visualization.\")\n",
    "\n",
    "    # Base covariance\n",
    "    S0 = cov_scale * np.array([[1.0, 0.6],\n",
    "                               [0.6, 1.4]])\n",
    "\n",
    "    # Rotation\n",
    "    theta = np.deg2rad(rotate_deg)\n",
    "    R = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                  [np.sin(theta),  np.cos(theta)]])\n",
    "    S1 = R @ S0 @ R.T\n",
    "    S2 = R.T @ S0 @ R  # slightly different orientation\n",
    "\n",
    "    # Means\n",
    "    mu1 = np.array([-separation/2, 0.0])\n",
    "    mu2 = np.array([+separation/2, 0.0])\n",
    "\n",
    "    X1 = rng.multivariate_normal(mu1, S1, size=n1)\n",
    "    X2 = rng.multivariate_normal(mu2, S2, size=n2)\n",
    "    return X1, X2\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# EM for 2-GMM WITH history (so sliders truly move parameters)\n",
    "# -----------------------------\n",
    "def gmm2_em_and_sample_history(\n",
    "    X1, X2,\n",
    "    n_iters=80, tol=1e-6, reg_covar=1e-6, n_samples=200, seed=0,\n",
    "    init=\"collapsed\",          # <-- NEW: \"from_sets\" (fast), \"random\", \"collapsed\" (slow+pedagogical)\n",
    "    damping=0.25,              # <-- NEW: alpha in (0,1], smaller => slower\n",
    "    early_stop=False           # <-- NEW: for demos keep False to run full n_iters\n",
    "):\n",
    "    X1 = np.asarray(X1, float)\n",
    "    X2 = np.asarray(X2, float)\n",
    "    X = np.vstack([X1, X2])\n",
    "    n, d = X.shape\n",
    "    rng = np.random.default_rng(seed)\n",
    "\n",
    "    # ---------- Initialization ----------\n",
    "    if init == \"from_sets\":\n",
    "        mu = np.stack([X1.mean(axis=0), X2.mean(axis=0)], axis=0)\n",
    "\n",
    "        def empirical_cov(A):\n",
    "            if len(A) <= 1:\n",
    "                return np.eye(d)\n",
    "            C = np.cov(A.T, bias=False)\n",
    "            if C.ndim == 0:\n",
    "                C = np.array([[float(C)]])\n",
    "            return C\n",
    "\n",
    "        Sigma = np.stack([empirical_cov(X1), empirical_cov(X2)], axis=0)\n",
    "        Sigma += reg_covar * np.eye(d)[None, :, :]\n",
    "        pi = np.array([len(X1), len(X2)], float)\n",
    "        pi = pi / pi.sum()\n",
    "\n",
    "    elif init == \"random\":\n",
    "        idx = rng.choice(n, size=2, replace=False)\n",
    "        mu = X[idx].copy()\n",
    "        C = np.cov(X.T, bias=False)\n",
    "        if C.ndim == 0:\n",
    "            C = np.array([[float(C)]])\n",
    "        Sigma = np.stack([C, C], axis=0) + reg_covar * np.eye(d)[None, :, :]\n",
    "        pi = np.array([0.5, 0.5], float)\n",
    "\n",
    "    elif init == \"collapsed\":\n",
    "        # both components start near the global mean -> EM must \"split\" them gradually\n",
    "        m = X.mean(axis=0)\n",
    "        jitter = 0.05 * rng.standard_normal((2, d))\n",
    "        mu = np.stack([m, m], axis=0) + jitter\n",
    "\n",
    "        C = np.cov(X.T, bias=False)\n",
    "        if C.ndim == 0:\n",
    "            C = np.array([[float(C)]])\n",
    "        Sigma = np.stack([C, C], axis=0) + reg_covar * np.eye(d)[None, :, :]\n",
    "        pi = np.array([0.5, 0.5], float)\n",
    "\n",
    "    elif init == \"pca_split\":\n",
    "        # Start both components near global mean but separated along the principal direction.\n",
    "        m = X.mean(axis=0)\n",
    "\n",
    "        C = np.cov(X.T, bias=False)\n",
    "        if C.ndim == 0:\n",
    "            C = np.array([[float(C)]])\n",
    "\n",
    "        # principal eigenvector\n",
    "        vals, vecs = np.linalg.eigh(C)\n",
    "        v = vecs[:, -1]                       # (d,)\n",
    "        s = np.sqrt(max(vals[-1], 1e-12))     # scale of spread along principal axis\n",
    "\n",
    "        # delta controls how \"far\" the initial means are; smaller -> slower but still breaks symmetry\n",
    "        split_scale = 0.35                    # try 0.25..0.6\n",
    "        delta = split_scale * s\n",
    "\n",
    "        mu = np.stack([m - delta * v, m + delta * v], axis=0)\n",
    "\n",
    "        # same covariance for both components at start (uninformative)\n",
    "        Sigma = np.stack([C, C], axis=0) + reg_covar * np.eye(d)[None, :, :]\n",
    "\n",
    "        # slightly asymmetric mixing weights to break symmetry further\n",
    "        pi = np.array([0.55, 0.45], float)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"init must be one of: 'from_sets', 'random', 'collapsed'.\")\n",
    "\n",
    "    # ---------- Helpers ----------\n",
    "    def log_gaussian_pdf(X, m, S):\n",
    "        L = np.linalg.cholesky(S)\n",
    "        Xm = X - m\n",
    "        v = np.linalg.solve(L, Xm.T)\n",
    "        quad = np.sum(v * v, axis=0)\n",
    "        log_det = 2.0 * np.sum(np.log(np.diag(L)))\n",
    "        return -0.5 * (d * np.log(2.0 * np.pi) + log_det + quad)\n",
    "\n",
    "    def logsumexp(a, axis=1):\n",
    "        amax = np.max(a, axis=axis, keepdims=True)\n",
    "        return (amax + np.log(np.sum(np.exp(a - amax), axis=axis, keepdims=True))).squeeze(axis)\n",
    "\n",
    "    # ---------- History ----------\n",
    "    loglik_path = []\n",
    "    pi_path, mu_path, Sigma_path = [], [], []\n",
    "\n",
    "    prev_ll = -np.inf\n",
    "\n",
    "    for it in range(n_iters):\n",
    "        # store snapshot (so slider can show evolution)\n",
    "        pi_path.append(pi.copy())\n",
    "        mu_path.append(mu.copy())\n",
    "        Sigma_path.append(Sigma.copy())\n",
    "\n",
    "        # E-step\n",
    "        log_r = np.zeros((n, 2))\n",
    "        for k in range(2):\n",
    "            log_r[:, k] = np.log(pi[k] + 1e-16) + log_gaussian_pdf(X, mu[k], Sigma[k])\n",
    "\n",
    "        ll = float(np.sum(logsumexp(log_r, axis=1)))\n",
    "        loglik_path.append(ll)\n",
    "\n",
    "        log_norm = logsumexp(log_r, axis=1)\n",
    "        r = np.exp(log_r - log_norm[:, None])\n",
    "\n",
    "        # optional early stop (disabled by default for pedagogy)\n",
    "        if early_stop and it > 0 and abs(ll - prev_ll) < tol * (1.0 + abs(prev_ll)):\n",
    "            break\n",
    "        prev_ll = ll\n",
    "\n",
    "        # M-step (compute \"new\" params)\n",
    "        Nk = r.sum(axis=0) + 1e-16\n",
    "        pi_new = Nk / n\n",
    "        mu_new = (r.T @ X) / Nk[:, None]\n",
    "\n",
    "        Sigma_new = np.zeros((2, d, d))\n",
    "        for k in range(2):\n",
    "            Xm = X - mu_new[k]\n",
    "            Sigma_new[k] = (Xm.T * r[:, k]) @ Xm / Nk[k]\n",
    "            Sigma_new[k] += reg_covar * np.eye(d)\n",
    "\n",
    "        # ---- NEW: damped update ----\n",
    "        a = float(damping)\n",
    "        pi = (1 - a) * pi + a * pi_new\n",
    "        pi = pi / np.sum(pi)  # renormalize\n",
    "\n",
    "        mu = (1 - a) * mu + a * mu_new\n",
    "        Sigma = (1 - a) * Sigma + a * Sigma_new\n",
    "\n",
    "    # final snapshot\n",
    "    pi_path.append(pi.copy())\n",
    "    mu_path.append(mu.copy())\n",
    "    Sigma_path.append(Sigma.copy())\n",
    "\n",
    "    # Sampling from final mixture\n",
    "    z = rng.choice(2, size=n_samples, p=pi)\n",
    "    samples = np.zeros((n_samples, d))\n",
    "    for k in range(2):\n",
    "        idx = np.where(z == k)[0]\n",
    "        if len(idx) == 0:\n",
    "            continue\n",
    "        samples[idx] = rng.multivariate_normal(mu[k], Sigma[k], size=len(idx))\n",
    "\n",
    "    params = {\n",
    "        \"pi\": pi,\n",
    "        \"mu\": mu,\n",
    "        \"Sigma\": Sigma,\n",
    "        \"loglik_path\": np.array(loglik_path, float),\n",
    "        \"history\": {\n",
    "            \"pi_path\": np.array(pi_path, float),\n",
    "            \"mu_path\": np.array(mu_path, float),\n",
    "            \"Sigma_path\": np.array(Sigma_path, float),\n",
    "        }\n",
    "    }\n",
    "    return params, samples, r\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Widget tool\n",
    "# -----------------------------\n",
    "def build_discriminative_vs_generative_widget(\n",
    "    *,\n",
    "    dataset_kwargs=None,\n",
    "    logreg_kwargs=None,\n",
    "    gmm_kwargs=None,\n",
    "    dims=(0, 1),\n",
    "    share_limits=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Creates an ipywidgets UI:\n",
    "      - Button \"Пересчитать\"\n",
    "      - Slider for LR iteration\n",
    "      - Slider for EM iteration\n",
    "      - 2 plots in a row (discriminative boundary + generative GMM)\n",
    "\n",
    "    Notes:\n",
    "      - Requires logistic_regression_gd_path, plot_logreg_snapshot, plot_gmm_snapshot already defined.\n",
    "      - Uses gmm2_em_and_sample_history defined above.\n",
    "    \"\"\"\n",
    "    if dataset_kwargs is None:\n",
    "        dataset_kwargs = dict(n1=100, n2=100, d=2, separation=2.6, cov_scale=0.9, rotate_deg=20.0, seed=0)\n",
    "    if logreg_kwargs is None:\n",
    "        logreg_kwargs = dict(\n",
    "            lr=0.1,\n",
    "            n_iters=20,\n",
    "            l2=1e-2,\n",
    "            fit_intercept=True,\n",
    "            seed=0,\n",
    "            lr_mode=\"warmup\",\n",
    "            warmup_power=3.0,\n",
    "            lr_max=None\n",
    "        )\n",
    "    if gmm_kwargs is None:\n",
    "        gmm_kwargs = gmm_kwargs = dict(\n",
    "            n_iters=100,\n",
    "            tol=1e-6,\n",
    "            reg_covar=1e-6,\n",
    "            n_samples=250,\n",
    "            seed=0,\n",
    "            init=\"pca_split\",\n",
    "            damping=0.20,\n",
    "            early_stop=False\n",
    "        )\n",
    "\n",
    "    # UI widgets\n",
    "    btn = widgets.Button(description=\"Пересчитать\", button_style=\"primary\", icon=\"refresh\")\n",
    "\n",
    "    t_lr = widgets.IntSlider(description=\"iter LR\", min=0, max=1, step=1, value=0, continuous_update=False)\n",
    "    t_em = widgets.IntSlider(description=\"iter EM\", min=0, max=1, step=1, value=0, continuous_update=False)\n",
    "\n",
    "    out = widgets.Output()\n",
    "\n",
    "    # Internal state\n",
    "    state = {\n",
    "        \"seed\": int(dataset_kwargs.get(\"seed\", 0)),\n",
    "        \"logreg_out\": None,\n",
    "        \"gmm_out\": None,\n",
    "    }\n",
    "\n",
    "    def recompute():\n",
    "        # Update seeds deterministically (so each click changes dataset)\n",
    "        state[\"seed\"] += 1\n",
    "        ds_kwargs = dict(dataset_kwargs)\n",
    "        ds_kwargs[\"seed\"] = state[\"seed\"]\n",
    "\n",
    "        # Generate data\n",
    "        X1, X2 = create_dataset(**ds_kwargs)\n",
    "\n",
    "        # Train discriminative model (uses YOUR earlier function)\n",
    "        w_path, b_path, loss_path = logistic_regression_gd_path(X1, X2, **logreg_kwargs)\n",
    "        logreg_out = {\"X1\": X1, \"X2\": X2, \"w_path\": w_path, \"b_path\": b_path, \"loss_path\": loss_path}\n",
    "\n",
    "        # Train generative model with EM history\n",
    "        params, samples, r = gmm2_em_and_sample_history(X1, X2, **gmm_kwargs)\n",
    "        gmm_out = {\"X1\": X1, \"X2\": X2, \"params\": params, \"samples\": samples, \"responsibilities\": r}\n",
    "\n",
    "        state[\"logreg_out\"] = logreg_out\n",
    "        state[\"gmm_out\"] = gmm_out\n",
    "\n",
    "        # Update slider ranges\n",
    "        t_lr.max = w_path.shape[0] - 1\n",
    "        t_lr.value = min(t_lr.value, t_lr.max)\n",
    "\n",
    "        # For EM, history length defines slider max\n",
    "        T_em = params[\"history\"][\"pi_path\"].shape[0]\n",
    "        t_em.max = T_em - 1\n",
    "        t_em.value = min(t_em.value, t_em.max)\n",
    "\n",
    "        draw()\n",
    "\n",
    "    def draw():\n",
    "        if state[\"logreg_out\"] is None or state[\"gmm_out\"] is None:\n",
    "            return\n",
    "\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "            # Left: discriminative snapshot\n",
    "            plot_logreg_snapshot(state[\"logreg_out\"], t=int(t_lr.value), ax=axes[0], dims=dims, title=True)\n",
    "\n",
    "            # Right: generative snapshot (uses params history, so ellipses move with t_em)\n",
    "            plot_gmm_snapshot(state[\"gmm_out\"], t=int(t_em.value), ax=axes[1], dims=dims, title=True, show_samples=True)\n",
    "\n",
    "            if share_limits:\n",
    "                X1 = state[\"logreg_out\"][\"X1\"][:, list(dims)]\n",
    "                X2 = state[\"logreg_out\"][\"X2\"][:, list(dims)]\n",
    "                Xall = np.vstack([X1, X2])\n",
    "                xmin, ymin = Xall.min(axis=0)\n",
    "                xmax, ymax = Xall.max(axis=0)\n",
    "                dx, dy = xmax - xmin, ymax - ymin\n",
    "                pad = 0.08\n",
    "                xmin -= pad * (dx + 1e-12); xmax += pad * (dx + 1e-12)\n",
    "                ymin -= pad * (dy + 1e-12); ymax += pad * (dy + 1e-12)\n",
    "                axes[0].set_xlim(xmin, xmax); axes[0].set_ylim(ymin, ymax)\n",
    "                axes[1].set_xlim(xmin, xmax); axes[1].set_ylim(ymin, ymax)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    # Wire events\n",
    "    def on_click(_):\n",
    "        recompute()\n",
    "\n",
    "    btn.on_click(on_click)\n",
    "\n",
    "    def on_slider_change(_):\n",
    "        draw()\n",
    "\n",
    "    t_lr.observe(on_slider_change, names=\"value\")\n",
    "    t_em.observe(on_slider_change, names=\"value\")\n",
    "\n",
    "    # Initial compute\n",
    "    recompute()\n",
    "\n",
    "    ui = widgets.VBox([\n",
    "        widgets.HBox([btn, t_lr, t_em]),\n",
    "        out\n",
    "    ])\n",
    "\n",
    "    return ui\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Usage (run this line)\n",
    "# -----------------------------\n",
    "ui = build_discriminative_vs_generative_widget()\n",
    "display(ui)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac22e4d6",
   "metadata": {},
   "source": [
    "## Основные типы генеративных моделей. Классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45c0b81",
   "metadata": {},
   "source": [
    "\n",
    "Внутри общей постановки генеративного обучения классифицировать модели не “по типу данных” (текст/картинки), а по **тому, как именно задаётся распределение $p_\\theta(x)$** и как мы с ним можем работать:\n",
    "\n",
    "1. можем ли мы вычислять $\\log p_\\theta(x)$ (точно или приближённо) для данного объекта $x$?\n",
    "2. как устроено семплирование $x\\sim p_\\theta$ (один проход, обратимые преобразования, многошаговый стохастический процесс и т.д.)?\n",
    "\n",
    "---\n",
    "\n",
    "В частности, часто выделяют три класса генеративных моделей:\n",
    "\n",
    "- **Явные (explicit) модели плотности** задают $p_\\theta(x)$ в явном виде и позволяют (точно или приближённо) вычислять $\\log p_\\theta(x)$ для произвольного объекта $x$. Сюда относятся, например, **авторегрессионные модели** и **нормализующие потоки**, где плотность выражается через детерминант якобиана обратимого преобразования.\n",
    "\n",
    "- **Неявные (implicit) генеративные модели** определяются через саму процедуру генерации\n",
    "  $$\n",
    "  z\\sim p(z),\\qquad x=g_\\theta(z),\n",
    "  $$\n",
    "  где $p(z)$ — простой prior (например, стандартное нормальное), а $g_\\theta$ — параметризованное отображение в пространство данных. Плотность $p_\\theta(x)$ при этом не выписывается в явном виде, и $\\log p_\\theta(x)$ недоступен; классический пример — **GAN**.\n",
    "\n",
    "- **Гибридные (латентные) модели** способны восстанавливать распределение над наблюдаемыми объектами, но в устройстве используют введение **латентных распределений** (то есть это не “просто explicit” и не “просто implicit”). Идея — упростить модель данных через явное выделение уровней/структуры в вероятностной модели; типичные представители — **VAE** и модели, которые можно понимать как их обобщение – диффузионные подходы."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d93027",
   "metadata": {},
   "source": [
    "<p align=\"center\">\n",
    "  <img src=\"images/lecture_1/gan_diff_vae.png\" style=\"width:60%;\">\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e07f8c",
   "metadata": {},
   "source": [
    "### Авторегрессионные генеративные модели (Autoregressive)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f190feff",
   "metadata": {},
   "source": [
    "Авторегрессионные (AR) модели задают **явную** плотность на сложных объектах $x$ (последовательностях, изображениях как сетке пикселей, токенах и т.п.) через факторизацию по правилу цепочки. Если $x=(x_1,\\dots,x_T)$, то\n",
    "\n",
    "$$\n",
    "p_\\theta(x)=p_\\theta(x_1,\\dots,x_T)=\\prod_{t=1}^{T} p_\\theta(x_t\\mid x_{<t}),\n",
    "\\qquad x_{<t}=(x_1,\\dots,x_{t-1}).\n",
    "$$\n",
    "\n",
    "Эта формула — математическое ядро всего подхода: мы раскладываем вероятность (плотность) цепочки на произведение более “простых” условных распределений. В качестве параметризации условных распределений обычно используют нейросеть, которая по контексту $x_{<t}$ выдаёт параметры распределения $p_\\theta(x_t\\mid x_{<t})$.\n",
    "\n",
    "Обучение максимально прямолинейно: это **MLE** по наблюдаемым данным, то есть минимизация отрицательного лог-правдоподобия (teacher forcing):\n",
    "$$\n",
    "\\hat\\theta=\\arg\\max_\\theta \\sum_{i=1}^n \\log p_\\theta(x^{(i)})\n",
    "=\\arg\\max_\\theta \\sum_{i=1}^n \\sum_{t=1}^{T} \\log p_\\theta\\!\\left(x^{(i)}_t \\mid x^{(i)}_{<t}\\right).\n",
    "$$\n",
    "В дискретном случае это эквивалентно сумме кросс-энтропий по позициям. Семплирование, напротив, является **последовательным**: сначала $x_1\\sim p_\\theta(\\cdot)$, затем $x_2\\sim p_\\theta(\\cdot\\mid x_1)$ и так далее до $x_T$. Таким образом мы автоматически получаем оценку вероятности объекта\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e44d274",
   "metadata": {},
   "source": [
    "#### Пример использования текстовой генеративной сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834a403",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output, HTML  # ✅ HTML для wrap\n",
    "\n",
    "from transformers import AutoProcessor, Qwen3VLForConditionalGeneration\n",
    "from transformers.generation.streamers import BaseStreamer\n",
    "\n",
    "MODEL_ID = \"Qwen/Qwen3-VL-2B-Instruct\"\n",
    "\n",
    "# --- load once ---\n",
    "if \"processor\" not in globals():\n",
    "    processor = AutoProcessor.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "\n",
    "if \"model\" not in globals():\n",
    "    model = Qwen3VLForConditionalGeneration.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        dtype=\"auto\",\n",
    "        device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "        trust_remote_code=True,\n",
    "    ).eval()\n",
    "    if not torch.cuda.is_available():\n",
    "        model = model.to(\"cpu\")\n",
    "\n",
    "\n",
    "def _html_escape(s: str) -> str:\n",
    "    return (s.replace(\"&\", \"&amp;\")\n",
    "             .replace(\"<\", \"&lt;\")\n",
    "             .replace(\">\", \"&gt;\")\n",
    "             .replace('\"', \"&quot;\")\n",
    "             .replace(\"'\", \"&#39;\"))\n",
    "\n",
    "\n",
    "def _render_wrapped(prefix_k: int, max_k: int, text: str):\n",
    "    \"\"\"\n",
    "    Печатает текст в HTML-блоке с переносами строк и переносом длинных токенов.\n",
    "    \"\"\"\n",
    "    safe = _html_escape(text)\n",
    "    display(HTML(\n",
    "        f\"\"\"\n",
    "        <div style=\"\n",
    "            width: 100%;\n",
    "            max-width: 100%;\n",
    "            box-sizing: border-box;\n",
    "            padding: 10px;\n",
    "            border: 1px solid #ddd;\n",
    "            border-radius: 8px;\n",
    "            font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, 'Liberation Mono', 'Courier New', monospace;\n",
    "            font-size: 13px;\n",
    "            line-height: 1.35;\n",
    "            white-space: pre-wrap;          /* ✅ сохраняем переводы строк + переносим */\n",
    "            word-wrap: break-word;          /* ✅ старый перенос */\n",
    "            overflow-wrap: anywhere;        /* ✅ перенос даже очень длинных “слов/токенов” */\n",
    "            word-break: break-word;\n",
    "        \">\n",
    "<b>Generated tokens prefix:</b> {prefix_k}/{max_k}\n",
    "\n",
    "{safe}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    ))\n",
    "\n",
    "\n",
    "class PrefixByTokenStreamer(BaseStreamer):\n",
    "    def __init__(self, tokenizer, prompt_len: int, max_new_tokens: int,\n",
    "                 skip_prompt: bool = True, skip_special_tokens: bool = True):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.prompt_len = int(prompt_len)\n",
    "        self.max_new_tokens = int(max_new_tokens)\n",
    "        self.skip_prompt = bool(skip_prompt)\n",
    "        self.skip_special_tokens = bool(skip_special_tokens)\n",
    "\n",
    "        self._remaining_prompt = self.prompt_len if self.skip_prompt else 0\n",
    "        self.generated_ids = []\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        _render_wrapped(0, self.max_new_tokens, \"\")\n",
    "\n",
    "    def put(self, value):\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            token_ids = value[0].tolist() if value.dim() == 2 else value.tolist()\n",
    "        else:\n",
    "            token_ids = list(value)\n",
    "\n",
    "        if self._remaining_prompt > 0:\n",
    "            if len(token_ids) <= self._remaining_prompt:\n",
    "                self._remaining_prompt -= len(token_ids)\n",
    "                return\n",
    "            token_ids = token_ids[self._remaining_prompt:]\n",
    "            self._remaining_prompt = 0\n",
    "\n",
    "        for tid in token_ids:\n",
    "            self.generated_ids.append(int(tid))\n",
    "            k = len(self.generated_ids)\n",
    "\n",
    "            text_k = self.tokenizer.decode(\n",
    "                self.generated_ids,\n",
    "                skip_special_tokens=self.skip_special_tokens,\n",
    "                clean_up_tokenization_spaces=False,\n",
    "            ).strip()\n",
    "\n",
    "            clear_output(wait=True)\n",
    "            _render_wrapped(k, self.max_new_tokens, text_k)\n",
    "\n",
    "    def end(self):\n",
    "        pass\n",
    "\n",
    "\n",
    "def _build_messages_text_only(user_text: str):\n",
    "    return [{\"role\": \"user\", \"content\": [{\"type\": \"text\", \"text\": user_text.strip()}]}]\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def stream_generate(user_text: str, max_new_tokens: int, temperature: float = 0.7, top_p: float = 0.9):\n",
    "    messages = _build_messages_text_only(user_text)\n",
    "\n",
    "    inputs = processor.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=True,\n",
    "        add_generation_prompt=True,\n",
    "        return_dict=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    inputs.pop(\"token_type_ids\", None)\n",
    "    inputs = inputs.to(model.device)\n",
    "\n",
    "    prompt_len = int(inputs[\"input_ids\"].shape[-1])\n",
    "    streamer = PrefixByTokenStreamer(\n",
    "        tokenizer=processor.tokenizer,\n",
    "        prompt_len=prompt_len,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        skip_prompt=True,\n",
    "        skip_special_tokens=True,\n",
    "    )\n",
    "\n",
    "    do_sample = temperature is not None and float(temperature) > 0.0\n",
    "\n",
    "    _ = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=int(max_new_tokens),\n",
    "        do_sample=do_sample,\n",
    "        temperature=float(temperature),\n",
    "        top_p=float(top_p),\n",
    "        streamer=streamer,\n",
    "        eos_token_id=processor.tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "\n",
    "# --- Notebook UI ---\n",
    "prompt_box = widgets.Textarea(\n",
    "    value=\"Кратко (5–7 предложений): чем диффузия концептуально отличается от GAN?\",\n",
    "    description=\"Prompt:\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"60px\"),\n",
    ")\n",
    "\n",
    "temp_slider = widgets.FloatSlider(\n",
    "    value=0.7, min=0.0, max=1.5, step=0.05,\n",
    "    description=\"temp:\", readout_format=\".2f\",\n",
    "    layout=widgets.Layout(width=\"60%\")\n",
    ")\n",
    "\n",
    "top_p_slider = widgets.FloatSlider(\n",
    "    value=0.9, min=0.1, max=1.0, step=0.01,\n",
    "    description=\"top_p:\", readout_format=\".2f\",\n",
    "    layout=widgets.Layout(width=\"60%\")\n",
    ")\n",
    "\n",
    "max_tok_slider = widgets.IntSlider(\n",
    "    value=64, min=16, max=2048, step=1,\n",
    "    description=\"max_tok:\",\n",
    "    layout=widgets.Layout(width=\"60%\")\n",
    ")\n",
    "\n",
    "btn = widgets.Button(description=\"Stream\", button_style=\"primary\")\n",
    "out = widgets.Output()\n",
    "\n",
    "def _on_click(_):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        text = prompt_box.value.strip()\n",
    "        if not text:\n",
    "            display(HTML(\"<b>Введите запрос.</b>\"))\n",
    "            return\n",
    "        stream_generate(\n",
    "            text,\n",
    "            max_new_tokens=int(max_tok_slider.value),\n",
    "            temperature=float(temp_slider.value),\n",
    "            top_p=float(top_p_slider.value),\n",
    "        )\n",
    "\n",
    "btn.on_click(_on_click)\n",
    "\n",
    "display(prompt_box, btn, temp_slider, top_p_slider, max_tok_slider, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5618b9fd",
   "metadata": {},
   "source": [
    "#### GAN (Generative Adversarial Networks)\n",
    "\n",
    "GAN — типичный представитель неявных-генеративных моделей: распределение $p_\\theta(x)$ задаётся **неявно** через процедуру генерации. Фиксируем prior $z\\sim p(z)$ (обычно $p(z)=\\mathcal N(0,I)$) и генератор $G_\\theta:\\mathcal Z\\to\\mathcal X$,\n",
    "$$\n",
    "x = G_\\theta(z),\n",
    "$$\n",
    "что индуцирует распределение $p_\\theta$ как отображения меры $p(z)$ в носитель $\\mathcal{X}$. При этом явная плотность $\\log p_\\theta(x)$, как правило, недоступна, так как от самой сети $G$ мы не требуем обратимости. Поэтому обучение не сводится к прямой максимизации правдоподобия.\n",
    "\n",
    "Обучение формулируется как состязательная оптимизация с дискриминатором $D_\\psi(x)\\in(0,1)$, отличающим реальные образцы $x\\sim p^*(x)$ от синтетических $x\\sim p_\\theta(x)$:\n",
    "$$\n",
    "\\min_\\theta \\max_\\psi\\ \n",
    "\\mathbb{E}_{x\\sim p^*}\\big[\\log D_\\psi(x)\\big]\n",
    "+\n",
    "\\mathbb{E}_{z\\sim p(z)}\\big[\\log\\big(1-D_\\psi(G_\\theta(z))\\big)\\big].\n",
    "$$\n",
    "критерий индуцирует минимизацию дивергенции между $p_\\theta$ и $p^*$ (в частности, связанной с Jensen–Shannon). Семплирование в GAN одношаговое (один прогон $G_\\theta$), что делает инференс быстрым и часто даёт высокое перцептуальное качество. Основные ограничения — нестабильность обучения и риск *mode collapse* (когда модель хорошо покрывает малую область \"существования\" реальных объектов, из-за чего деряется разнообразие генерируемых объектов).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4acc728",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from PIL import Image\n",
    "\n",
    "from pytorch_pretrained_biggan import BigGAN, one_hot_from_int, truncated_noise_sample\n",
    "\n",
    "# ---- Load model (once) ----\n",
    "MODEL_NAME = \"biggan-deep-256\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if \"biggan\" not in globals():\n",
    "    biggan = BigGAN.from_pretrained(MODEL_NAME).to(device).eval()\n",
    "\n",
    "def _tensor_to_pil(img_t: torch.Tensor) -> Image.Image:\n",
    "    x = (img_t.clamp(-1, 1) + 1.0) / 2.0\n",
    "    x = (x * 255.0).to(torch.uint8).permute(1, 2, 0).cpu().numpy()\n",
    "    return Image.fromarray(x)\n",
    "\n",
    "def _make_grid(images, cols=4):  # ✅ fixed cols=4\n",
    "    n = len(images)\n",
    "    cols = 4\n",
    "    rows = int(np.ceil(n / cols))\n",
    "    fig = plt.figure(figsize=(3.2 * cols, 3.2 * rows))\n",
    "    for i, im in enumerate(images, 1):\n",
    "        ax = fig.add_subplot(rows, cols, i)\n",
    "        ax.imshow(im)\n",
    "        ax.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "@torch.inference_mode()\n",
    "def generate_biggan(class_id: int, n: int, truncation: float, seed: int):\n",
    "    if seed < 0:\n",
    "        seed = np.random.randint(65000)\n",
    "    noise = truncated_noise_sample(truncation=truncation, batch_size=n, seed=seed)\n",
    "    noise = torch.from_numpy(noise).to(device)\n",
    "\n",
    "    class_vec = one_hot_from_int(int(class_id), batch_size=n)\n",
    "    class_vec = torch.from_numpy(class_vec).to(device)\n",
    "\n",
    "    out = biggan(noise, class_vec, truncation)\n",
    "    images = [_tensor_to_pil(out[i]) for i in range(out.shape[0])]\n",
    "    return images\n",
    "\n",
    "# ---- Widgets UI ----\n",
    "class_id_slider = widgets.IntSlider(\n",
    "    value=207, min=0, max=999, step=1,\n",
    "    description=\"class_id:\",\n",
    "    layout=widgets.Layout(width=\"520px\")\n",
    ")\n",
    "\n",
    "n_slider = widgets.IntSlider(\n",
    "    value=4, min=1, max=16, step=1,\n",
    "    description=\"n:\",\n",
    "    layout=widgets.Layout(width=\"520px\")\n",
    ")\n",
    "\n",
    "trunc_slider = widgets.FloatSlider(\n",
    "    value=0.4, min=0.1, max=1.0, step=0.05,\n",
    "    description=\"trunc:\",\n",
    "    readout_format=\".2f\",\n",
    "    layout=widgets.Layout(width=\"520px\")\n",
    ")\n",
    "\n",
    "seed_box = widgets.IntText(\n",
    "    value=-1,\n",
    "    description=\"seed:\",\n",
    "    layout=widgets.Layout(width=\"240px\")\n",
    ")\n",
    "\n",
    "btn_gen = widgets.Button(description=\"Generate (BigGAN)\", button_style=\"primary\")\n",
    "btn_rand = widgets.Button(description=\"Random class\", button_style=\"info\")\n",
    "out = widgets.Output()\n",
    "\n",
    "def _on_rand(_):\n",
    "    class_id_slider.value = int(np.random.randint(0, 1000))\n",
    "\n",
    "def _on_gen(_):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        images = generate_biggan(\n",
    "            class_id=int(class_id_slider.value),\n",
    "            n=int(n_slider.value),\n",
    "            truncation=float(trunc_slider.value),\n",
    "            seed=int(seed_box.value),\n",
    "        )\n",
    "        _make_grid(images, cols=4)  # ✅ always 4\n",
    "\n",
    "btn_rand.on_click(_on_rand)\n",
    "btn_gen.on_click(_on_gen)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<b>BigGAN (class-conditional GAN on ImageNet)</b><br>Выбираем класс по индексу 0..999\"),\n",
    "    widgets.HBox([class_id_slider]),\n",
    "    widgets.HBox([seed_box, btn_rand]),\n",
    "    n_slider,\n",
    "    trunc_slider,\n",
    "    btn_gen,\n",
    "    out\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cb6969",
   "metadata": {},
   "source": [
    "### VAE (Variational Autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5d8305",
   "metadata": {},
   "source": [
    "VAE — канонический пример *латентной* генеративной модели: вводится скрытая переменная $z\\in\\mathcal Z$ и задаётся совместное распределение\n",
    "\n",
    "$$\n",
    "p_\\theta(x,z)=p_\\theta(x\\mid z)\\,p(z), \\quad\\quad p_\\theta(x)=\\int p_\\theta(x\\mid z)\\,p(z)\\,dz\n",
    "$$\n",
    "\n",
    "При этом $p(z)$ берут как некий простой prior (обычно $p(z)=\\mathcal N(0,I)$). Обучать и использовать условных генератор/декодер $p_\\theta(x\\mid z)$ оказывается намного проще и стабильнее. Однако у нас появляется потребность в приближении еще одного распределения $q_\\phi(z\\mid x)$ – будем приближать второй нейросетью (энкодером). Тогда при обучении оптимизируют нижнюю вариационную оценку лог-правдоподобия (ELBO):\n",
    "\n",
    "$$\n",
    "\\log p_\\theta(x)\\ge \n",
    "\\mathcal L_{\\mathrm{ELBO}}(x;\\theta,\\phi)\n",
    "=\n",
    "\\mathbb E_{z\\sim q_\\phi(z\\mid x)}\\big[\\log p_\\theta(x\\mid z)\\big]\n",
    "-\n",
    "\\mathrm{KL}\\!\\big(q_\\phi(z\\mid x)\\,\\|\\,p(z)\\big) \\longrightarrow \\max\n",
    "$$\n",
    "\n",
    "Семплирование после обучения тривиально: сначала $z\\sim p(z)$, затем $x\\sim p_\\theta(x\\mid z)$; для контролируемой генерации аналогично используют условные варианты $p_\\theta(x\\mid z,y)$ и $q_\\phi(z\\mid x,y)$.\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"images/lecture_1/vae.png\" style=\"width:60%;\">\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad87429",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Audio, clear_output\n",
    "from huggingface_hub import snapshot_download\n",
    "from datasets import load_dataset, Audio as HFAudio\n",
    "from itertools import islice\n",
    "\n",
    "# ----------------------------\n",
    "# LibriSpeech streaming settings\n",
    "# ----------------------------\n",
    "LIBRISPEECH_SPLIT = \"validation.clean\"\n",
    "LIBRISPEECH_SKIP_MAX = 2000  # больше -> случайнее, но потенциально медленнее\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Download model repo from Hugging Face (code + weights)\n",
    "# ----------------------------\n",
    "MODEL_REPO = \"earlab/EAR_VAE\"\n",
    "LOCAL_DIR = os.path.join(os.getcwd(), \"hf_ear_vae\")  # local cache folder\n",
    "\n",
    "repo_path = snapshot_download(\n",
    "    repo_id=MODEL_REPO,\n",
    "    local_dir=LOCAL_DIR,\n",
    "    local_dir_use_symlinks=False,\n",
    "    revision=\"main\",\n",
    ")\n",
    "\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.insert(0, repo_path)\n",
    "\n",
    "from model.ear_vae import EAR_VAE  # provided by the repo\n",
    "\n",
    "CONFIG_PATH = os.path.join(repo_path, \"config\", \"ear_vae_v2.json\")\n",
    "WEIGHT_PATH = os.path.join(repo_path, \"pretrained_weight\", \"ear_vae_v2_48k.pyt\")\n",
    "\n",
    "TARGET_SR = 48000\n",
    "DOWNSAMPLE_RATIO = 960  # aligns T -> T/960 latents\n",
    "\n",
    "with open(CONFIG_PATH, \"r\") as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def _unwrap_state_dict(ckpt):\n",
    "    \"\"\"Return a pure state_dict name->tensor.\"\"\"\n",
    "    if not isinstance(ckpt, dict):\n",
    "        return ckpt\n",
    "    for key in [\"state_dict\", \"model\", \"net\", \"ema\", \"generator\"]:\n",
    "        if key in ckpt and isinstance(ckpt[key], dict):\n",
    "            return ckpt[key]\n",
    "    return ckpt\n",
    "\n",
    "# ---- Load model once (robust to optional bottleneck transformer mismatch) ----\n",
    "if \"ear_vae\" not in globals():\n",
    "    ear_vae = EAR_VAE(model_config=cfg).to(device)\n",
    "\n",
    "    ckpt = torch.load(WEIGHT_PATH, map_location=\"cpu\")\n",
    "    sd = _unwrap_state_dict(ckpt)\n",
    "    sd = {k.replace(\"module.\", \"\"): v for k, v in sd.items()}\n",
    "\n",
    "    has_transformer_weights = any(k.startswith(\"transformers.\") for k in sd.keys())\n",
    "    if (not has_transformer_weights) and hasattr(ear_vae, \"transformers\"):\n",
    "        # checkpoint was trained without transformer bottleneck => disable it\n",
    "        ear_vae.transformers = nn.Identity()\n",
    "\n",
    "    incompat = ear_vae.load_state_dict(sd, strict=False)\n",
    "    if len(incompat.missing_keys) or len(incompat.unexpected_keys):\n",
    "        print(\"WARNING: state_dict incompatibilities detected.\")\n",
    "        print(\"Missing keys (first 20):\", incompat.missing_keys[:20])\n",
    "        print(\"Unexpected keys (first 20):\", incompat.unexpected_keys[:20])\n",
    "\n",
    "    ear_vae.eval()\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Utilities: load / preprocess audio\n",
    "# ----------------------------\n",
    "def _load_audio_from_upload(upload_widget):\n",
    "    \"\"\"Returns waveform tensor (C,T) float32 and sample rate.\"\"\"\n",
    "    if not upload_widget.value:\n",
    "        return None, None\n",
    "    item = next(iter(upload_widget.value.values()))\n",
    "    raw = item[\"content\"]\n",
    "    bio = io.BytesIO(raw)\n",
    "    audio_np, sr = sf.read(bio, dtype=\"float32\", always_2d=True)  # (T,C)\n",
    "    wav = torch.from_numpy(audio_np).T.contiguous()               # (C,T)\n",
    "    return wav, int(sr)\n",
    "\n",
    "def _to_stereo(wav_ct):\n",
    "    if wav_ct.ndim != 2:\n",
    "        raise ValueError(\"Expected waveform shape (C,T).\")\n",
    "    if wav_ct.shape[0] == 1:\n",
    "        return torch.cat([wav_ct, wav_ct], dim=0)\n",
    "    return wav_ct[:2]\n",
    "\n",
    "def _resample_if_needed(wav_ct, sr, target_sr=TARGET_SR):\n",
    "    if sr == target_sr:\n",
    "        return wav_ct\n",
    "    resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sr)\n",
    "    return resampler(wav_ct)\n",
    "\n",
    "def _crop_or_pad_to_seconds_and_multiple(wav_ct, sr, seconds, multiple=DOWNSAMPLE_RATIO):\n",
    "    T_target = int(sr * float(seconds))\n",
    "    if wav_ct.shape[-1] >= T_target:\n",
    "        wav_ct = wav_ct[..., :T_target]\n",
    "    else:\n",
    "        wav_ct = torch.nn.functional.pad(wav_ct, (0, T_target - wav_ct.shape[-1]))\n",
    "\n",
    "    T = wav_ct.shape[-1]\n",
    "    Tm = (T // multiple) * multiple\n",
    "    if Tm < multiple:\n",
    "        Tm = multiple\n",
    "    if Tm != T:\n",
    "        wav_ct = wav_ct[..., :Tm] if T >= Tm else torch.nn.functional.pad(wav_ct, (0, Tm - T))\n",
    "    return wav_ct\n",
    "\n",
    "def _peak_normalize(wav_ct, eps=1e-8):\n",
    "    peak = float(wav_ct.abs().max())\n",
    "    if peak < eps:\n",
    "        return wav_ct\n",
    "    return (wav_ct / peak).clamp(-1, 1)\n",
    "\n",
    "def _random_fragment(wav_ct, sr, seconds):\n",
    "    \"\"\"Take a random contiguous fragment of length seconds; pad if needed.\"\"\"\n",
    "    T_need = int(sr * float(seconds))\n",
    "    T = wav_ct.shape[-1]\n",
    "    if T >= T_need:\n",
    "        start = np.random.randint(0, T - T_need + 1) if (T - T_need) > 0 else 0\n",
    "        return wav_ct[..., start:start + T_need]\n",
    "    return torch.nn.functional.pad(wav_ct, (0, T_need - T))\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Random LibriSpeech fallback (streaming, decode via bytes)\n",
    "# ----------------------------\n",
    "if \"ls_stream\" not in globals():\n",
    "    ls_stream = load_dataset(\"openslr/librispeech_asr\", split=LIBRISPEECH_SPLIT, streaming=True)\n",
    "    ls_stream = ls_stream.cast_column(\"audio\", HFAudio(decode=False))\n",
    "\n",
    "def _read_audio_meta(audio_meta):\n",
    "    \"\"\"\n",
    "    Extract wav (C,T) float32 and sr from audio_meta.\n",
    "    Prefers audio_meta['bytes'] for streaming. Falls back to existing path only.\n",
    "    \"\"\"\n",
    "    if not isinstance(audio_meta, dict):\n",
    "        raise RuntimeError(f\"audio_meta has unexpected type: {type(audio_meta)}\")\n",
    "\n",
    "    # decode=True case\n",
    "    if \"array\" in audio_meta and \"sampling_rate\" in audio_meta and audio_meta[\"array\"] is not None:\n",
    "        arr = audio_meta[\"array\"]\n",
    "        sr = int(audio_meta[\"sampling_rate\"])\n",
    "        if arr.ndim == 1:\n",
    "            arr = arr[:, None]\n",
    "        wav = torch.from_numpy(arr.astype(\"float32\")).T.contiguous()  # (C,T)\n",
    "        return wav, sr\n",
    "\n",
    "    # streaming decode=False: bytes is the reliable route\n",
    "    b = audio_meta.get(\"bytes\", None)\n",
    "    if b is not None:\n",
    "        audio_np, sr = sf.read(io.BytesIO(b), dtype=\"float32\", always_2d=True)  # (T,C)\n",
    "        wav = torch.from_numpy(audio_np).T.contiguous()\n",
    "        return wav, int(sr)\n",
    "\n",
    "    # path fallback only if it exists (often it's just basename and does NOT exist)\n",
    "    path = audio_meta.get(\"path\", None)\n",
    "    if path is not None and os.path.exists(path):\n",
    "        audio_np, sr = sf.read(path, dtype=\"float32\", always_2d=True)\n",
    "        wav = torch.from_numpy(audio_np).T.contiguous()\n",
    "        return wav, int(sr)\n",
    "\n",
    "    raise RuntimeError(f\"Cannot decode audio_meta. keys={list(audio_meta.keys())}\")\n",
    "\n",
    "def _get_random_librispeech_fragment(seconds):\n",
    "    \"\"\"\n",
    "    Returns stereo waveform (C,T) float32 and sr.\n",
    "    Each call: skip random K items in streaming iterator, then take next sample.\n",
    "    \"\"\"\n",
    "    k = int(np.random.randint(0, LIBRISPEECH_SKIP_MAX + 1))\n",
    "    it = iter(ls_stream)\n",
    "    sample = next(islice(it, k, None))\n",
    "    wav, sr = _read_audio_meta(sample[\"audio\"])\n",
    "    wav = _to_stereo(wav)\n",
    "    wav = _random_fragment(wav, sr, seconds=float(seconds))\n",
    "    return wav, sr\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Encode -> latent -> decode (mu/sigma and optional sampling)\n",
    "# ----------------------------\n",
    "@torch.inference_mode()\n",
    "def encode_latent_and_reconstruct(wav_ct, use_sample=True):\n",
    "    \"\"\"\n",
    "    wav_ct: (C,T) float32 on CPU\n",
    "    Returns: mu, sigma, z, recon, kl_est (all CPU)\n",
    "    \"\"\"\n",
    "    wav = wav_ct.to(device, torch.float32).unsqueeze(0)  # (1,C,T)\n",
    "\n",
    "    status = ear_vae.encoder(wav)                         # (1, 2*Cz, Tz)\n",
    "    mu, scale = status.chunk(2, dim=1)                    # each (1,Cz,Tz)\n",
    "    sigma = torch.nn.functional.softplus(scale)           # stddev\n",
    "\n",
    "    if use_sample:\n",
    "        eps = torch.randn_like(mu)                        # truly random\n",
    "        z = mu + sigma * eps\n",
    "    else:\n",
    "        z = mu\n",
    "\n",
    "    recon = ear_vae.decode(z)                             # (1,C,T)\n",
    "\n",
    "    var = sigma * sigma + 1e-6\n",
    "    logvar = torch.log(var)\n",
    "    kl = (mu * mu + var - logvar - 1).sum(1).mean().item()\n",
    "\n",
    "    return (\n",
    "        mu.squeeze(0).detach().cpu(),\n",
    "        sigma.squeeze(0).detach().cpu(),\n",
    "        z.squeeze(0).detach().cpu(),\n",
    "        recon.squeeze(0).detach().cpu(),\n",
    "        float(kl),\n",
    "    )\n",
    "\n",
    "@torch.inference_mode()\n",
    "def sample_from_prior(seconds=2.5):\n",
    "    seconds = float(seconds)\n",
    "    T = int(TARGET_SR * seconds)\n",
    "    T = max(DOWNSAMPLE_RATIO, (T // DOWNSAMPLE_RATIO) * DOWNSAMPLE_RATIO)\n",
    "    Tz = T // DOWNSAMPLE_RATIO\n",
    "    Cz = int(cfg[\"decoder\"][\"config\"][\"latent_dim\"])  # typically 64\n",
    "    z = torch.randn(1, Cz, Tz, device=device, dtype=torch.float32)  # truly random\n",
    "    y = ear_vae.decode(z).squeeze(0).detach().cpu()\n",
    "    return y\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Visualization\n",
    "# ----------------------------\n",
    "def _plot_waveforms(orig, recon, sr=TARGET_SR, title=\"Waveforms\"):\n",
    "    T = orig.shape[-1]\n",
    "    max_plot = min(T, sr * 3)\n",
    "    t = np.arange(max_plot) / sr\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.plot(t, orig[0, :max_plot].numpy(), linewidth=1.0, label=\"orig L\")\n",
    "    ax.plot(t, recon[0, :max_plot].numpy(), linewidth=1.0, label=\"recon L\", alpha=0.8)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"time (s)\")\n",
    "    ax.set_ylabel(\"amplitude\")\n",
    "    ax.grid(True, linewidth=0.3)\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def _plot_latent_heatmap(z, title=\"Latent z heatmap (channels × time)\"):\n",
    "    Cz, Tz = z.shape\n",
    "    c_show = min(Cz, 64)\n",
    "    t_show = min(Tz, 256)\n",
    "    zz = z[:c_show, :t_show].numpy()\n",
    "\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    im = ax.imshow(zz, aspect=\"auto\", origin=\"lower\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"latent time index\")\n",
    "    ax.set_ylabel(\"latent channel\")\n",
    "    plt.colorbar(im, ax=ax, fraction=0.025, pad=0.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def _plot_mu_sigma_stats(mu, sigma):\n",
    "    fig = plt.figure(figsize=(12, 4))\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.hist(mu.flatten().numpy(), bins=60)\n",
    "    ax1.set_title(\"mu histogram\")\n",
    "    ax1.grid(True, linewidth=0.3)\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.hist(sigma.flatten().numpy(), bins=60)\n",
    "    ax2.set_title(\"sigma histogram\")\n",
    "    ax2.grid(True, linewidth=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ----------------------------\n",
    "# 5) ipywidgets UI\n",
    "# ----------------------------\n",
    "upload = widgets.FileUpload(accept=\".wav,.flac,.ogg\", multiple=False)\n",
    "\n",
    "seconds_slider = widgets.FloatSlider(\n",
    "    value=2.5, min=0.5, max=10.0, step=0.5,\n",
    "    description=\"seconds:\",\n",
    "    layout=widgets.Layout(width=\"60%\")\n",
    ")\n",
    "\n",
    "latent_mode = widgets.ToggleButtons(\n",
    "    options=[(\"mean (deterministic)\", \"mean\"), (\"sample (stochastic)\", \"sample\")],\n",
    "    description=\"latent:\",\n",
    ")\n",
    "\n",
    "btn_recon = widgets.Button(description=\"Encode → Latent → Reconstruct\", button_style=\"primary\")\n",
    "btn_prior = widgets.Button(description=\"Sample z ~ N(0,I) → Decode\", button_style=\"warning\")\n",
    "\n",
    "out = widgets.Output()\n",
    "\n",
    "def _run_recon(_):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "\n",
    "        wav, sr = _load_audio_from_upload(upload)\n",
    "        source = \"user upload\"\n",
    "        if wav is None:\n",
    "            wav, sr = _get_random_librispeech_fragment(seconds=float(seconds_slider.value))\n",
    "            source = f\"LibriSpeech random ({LIBRISPEECH_SPLIT})\"\n",
    "\n",
    "        wav = _to_stereo(wav)\n",
    "        wav = _resample_if_needed(wav, sr, TARGET_SR)\n",
    "        wav = _crop_or_pad_to_seconds_and_multiple(wav, TARGET_SR, seconds=float(seconds_slider.value))\n",
    "        wav = _peak_normalize(wav)\n",
    "\n",
    "        use_sample = (latent_mode.value == \"sample\")\n",
    "        mu, sigma, z, recon, kl = encode_latent_and_reconstruct(wav, use_sample=use_sample)\n",
    "        recon = _peak_normalize(recon)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Source: {source}\")\n",
    "        print(f\"Input: (C,T)={tuple(wav.shape)}, SR={TARGET_SR}\")\n",
    "        print(f\"Latent: mu/sigma/z shapes = {tuple(mu.shape)} ; KL estimate ≈ {kl:.3f}\\n\")\n",
    "\n",
    "        display(widgets.HTML(\"<b>Original audio</b>\"))\n",
    "        display(Audio(wav.numpy(), rate=TARGET_SR))\n",
    "\n",
    "        display(widgets.HTML(\"<b>Reconstructed audio</b>\"))\n",
    "        display(Audio(recon.numpy(), rate=TARGET_SR))\n",
    "\n",
    "        _plot_waveforms(wav, recon, sr=TARGET_SR, title=\"Original vs Reconstruction (Left channel)\")\n",
    "        _plot_mu_sigma_stats(mu, sigma)\n",
    "        _plot_latent_heatmap(z)\n",
    "\n",
    "def _run_prior(_):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        seconds = float(seconds_slider.value)\n",
    "        y = sample_from_prior(seconds=seconds)\n",
    "        y = _to_stereo(y)\n",
    "        y = _peak_normalize(y)\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Prior sample: (C,T)={tuple(y.shape)}, SR={TARGET_SR}, seconds≈{seconds}\\n\")\n",
    "\n",
    "        display(widgets.HTML(\"<b>Generated audio from prior (z ~ N(0,I))</b>\"))\n",
    "        display(Audio(y.numpy(), rate=TARGET_SR))\n",
    "\n",
    "        fig = plt.figure(figsize=(12, 3))\n",
    "        ax = fig.add_subplot(1, 1, 1)\n",
    "        T = min(y.shape[-1], TARGET_SR * 3)\n",
    "        t = np.arange(T) / TARGET_SR\n",
    "        ax.plot(t, y[0, :T].numpy(), linewidth=1.0)\n",
    "        ax.set_title(\"Prior-sampled waveform (Left channel)\")\n",
    "        ax.set_xlabel(\"time (s)\")\n",
    "        ax.grid(True, linewidth=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "btn_recon.on_click(_run_recon)\n",
    "btn_prior.on_click(_run_prior)\n",
    "\n",
    "display(\n",
    "    widgets.VBox([\n",
    "        widgets.HTML(\"<b>VAE demo on audio (earlab/EAR_VAE): upload or random LibriSpeech → latent → reconstruction</b>\"),\n",
    "        upload,\n",
    "        seconds_slider,\n",
    "        latent_mode,\n",
    "        widgets.HBox([btn_recon, btn_prior]),\n",
    "        out\n",
    "    ])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e566ff39",
   "metadata": {},
   "source": [
    "#### Диффузионные модели (Diffusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb28c588",
   "metadata": {},
   "source": [
    "\n",
    "Диффузионные модели представляют генерацию как результат **обращения последовательного зашумления данных**. В отличие от GAN, где генерация происходит за один шаг, и в отличие от VAE, где генерация — это декодирование одной латентной переменной, диффузионные модели строят объект **итеративно**, постепенно восстанавливая структуру данных из шума.\n",
    "\n",
    "Концептуально вводится прямой процесс, который шаг за шагом разрушает структуру исходных данных $x_0$, превращая их в простой шумовой распределённый объект $x_T$ (обычно близкий к $\\mathcal N(0,I)$). Этот процесс фиксирован и не обучается. Генерация же соответствует обратному процессу: начиная с шума, модель последовательно строит всё более структурированные состояния, приближаясь к распределению данных. Таким образом, генеративная модель реализует цепочку переходов\n",
    "$$\n",
    "x_T \\rightarrow x_{T-1} \\rightarrow \\dots \\rightarrow x_0,\n",
    "$$\n",
    "где каждый шаг аппроксимируется нейросетью.\n",
    "\n",
    "С точки зрения обучения, диффузионные модели относятся к *likelihood-based* генеративным моделям: они оптимизируют вариационную нижнюю оценку на $\\log p_\\theta(x)$, но делают это через локальные задачи восстановления структуры на каждом шаге цепочки. В результате обучение оказывается **стабильным**, без состязательной динамики, характерной для GAN, и с хорошим покрытием мод распределения данных.\n",
    "\n",
    "Ключевым практическим свойством диффузионных моделей является высокое качество и разнообразие генерации при цене **многократного итеративного инференса**. Современные архитектуры смягчают этот недостаток за счёт уменьшения числа шагов или переноса диффузии в латентное пространство (Latent Diffusion), где итеративный процесс работает над компактным представлением объекта, а декодер восстанавливает данные в исходном пространстве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ad3534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess, importlib, os\n",
    "import torch\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "\n",
    "from diffusers import StableDiffusionXLPipeline, DEISMultistepScheduler\n",
    "\n",
    "# ----------------------------\n",
    "# Model / device setup\n",
    "# ----------------------------\n",
    "MODEL_ID = \"stabilityai/stable-diffusion-xl-base-1.0\"\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = \"cuda\" if use_cuda else \"cpu\"\n",
    "dtype = torch.float16 if use_cuda else torch.float32\n",
    "\n",
    "# Optional: HF token (needed if model access is gated in your account)\n",
    "# Either set env var HF_TOKEN in your notebook environment, or leave None.\n",
    "HF_TOKEN = os.environ.get(\"HF_TOKEN\", None)\n",
    "\n",
    "# Load pipeline once\n",
    "if \"sdxl_pipe\" not in globals():\n",
    "    sdxl_pipe = StableDiffusionXLPipeline.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        torch_dtype=dtype,\n",
    "        use_safetensors=True,\n",
    "        variant=\"fp16\" if use_cuda else None,\n",
    "        token=HF_TOKEN,                  # safe if None\n",
    "    )\n",
    "    # Set DEIS scheduler\n",
    "    sdxl_pipe.scheduler = DEISMultistepScheduler.from_config(sdxl_pipe.scheduler.config)\n",
    "\n",
    "    if use_cuda:\n",
    "        sdxl_pipe = sdxl_pipe.to(\"cuda\")\n",
    "        # Speed/memory tweaks (safe defaults)\n",
    "        try:\n",
    "            sdxl_pipe.enable_attention_slicing()\n",
    "        except Exception:\n",
    "            pass\n",
    "    else:\n",
    "        sdxl_pipe = sdxl_pipe.to(\"cpu\")\n",
    "\n",
    "    # For reproducibility you could set a generator, but user didn't ask; keep stochastic.\n",
    "    sdxl_pipe.set_progress_bar_config(disable=True)\n",
    "\n",
    "def _show_images(imgs, cols=2, max_w=512):\n",
    "    \"\"\"Simple grid display without matplotlib (PIL + notebook).\"\"\"\n",
    "    if not imgs:\n",
    "        return\n",
    "    cols = max(1, int(cols))\n",
    "    rows = (len(imgs) + cols - 1) // cols\n",
    "\n",
    "    # Resize for consistent display\n",
    "    resized = []\n",
    "    for im in imgs:\n",
    "        if isinstance(im, Image.Image):\n",
    "            w, h = im.size\n",
    "            if w > max_w:\n",
    "                nh = int(h * (max_w / w))\n",
    "                im = im.resize((max_w, nh))\n",
    "            resized.append(im)\n",
    "        else:\n",
    "            resized.append(im)\n",
    "\n",
    "    # Create a grid canvas\n",
    "    widths = [im.size[0] for im in resized]\n",
    "    heights = [im.size[1] for im in resized]\n",
    "    cell_w = max(widths)\n",
    "    cell_h = max(heights)\n",
    "\n",
    "    grid = Image.new(\"RGB\", (cell_w * cols, cell_h * rows), (255, 255, 255))\n",
    "    for idx, im in enumerate(resized):\n",
    "        r = idx // cols\n",
    "        c = idx % cols\n",
    "        x0, y0 = c * cell_w, r * cell_h\n",
    "        # center in cell\n",
    "        dx = (cell_w - im.size[0]) // 2\n",
    "        dy = (cell_h - im.size[1]) // 2\n",
    "        grid.paste(im, (x0 + dx, y0 + dy))\n",
    "    display(grid)\n",
    "\n",
    "@torch.inference_mode()\n",
    "def run_sdxl_deis(prompt: str, nfe: int, guidance: float, h: int, w: int, num_images: int):\n",
    "    prompt = prompt.strip()\n",
    "    nfe = int(nfe)\n",
    "\n",
    "    # SDXL constraints: width/height should be multiples of 8, typically 1024 for best results\n",
    "    h = int(h) - (int(h) % 8)\n",
    "    w = int(w) - (int(w) % 8)\n",
    "\n",
    "    out = sdxl_pipe(\n",
    "        prompt=prompt,\n",
    "        num_inference_steps=nfe,     # NFE\n",
    "        guidance_scale=float(guidance),\n",
    "        height=h,\n",
    "        width=w,\n",
    "        num_images_per_prompt=int(num_images),\n",
    "    )\n",
    "    return out.images\n",
    "\n",
    "# ----------------------------\n",
    "# Widgets UI\n",
    "# ----------------------------\n",
    "prompt_box = widgets.Textarea(\n",
    "    value=\"A high-detail studio photo of a small robotic arm assembling a tiny circuit board, realistic lighting, shallow depth of field\",\n",
    "    description=\"Prompt:\",\n",
    "    layout=widgets.Layout(width=\"100%\", height=\"120px\"),\n",
    ")\n",
    "\n",
    "nfe_slider = widgets.IntSlider(\n",
    "    value=25, min=5, max=80, step=1,\n",
    "    description=\"NFE:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "\n",
    "guidance_slider = widgets.FloatSlider(\n",
    "    value=6.0, min=0.0, max=12.0, step=0.5,\n",
    "    description=\"CFG:\",\n",
    "    readout_format=\".1f\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "\n",
    "size_dropdown = widgets.Dropdown(\n",
    "    options=[\n",
    "        (\"1024×1024 (default SDXL)\", (1024, 1024)),\n",
    "        (\"1152×896\", (1152, 896)),\n",
    "        (\"896×1152\", (896, 1152)),\n",
    "        (\"832×1216\", (832, 1216)),\n",
    "        (\"1216×832\", (1216, 832)),\n",
    "    ],\n",
    "    value=(1024, 1024),\n",
    "    description=\"Size:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "\n",
    "num_images_slider = widgets.IntSlider(\n",
    "    value=1, min=1, max=4, step=1,\n",
    "    description=\"#img:\",\n",
    "    layout=widgets.Layout(width=\"70%\"),\n",
    ")\n",
    "\n",
    "btn = widgets.Button(description=\"Generate (SDXL + DEIS)\", button_style=\"primary\")\n",
    "out = widgets.Output()\n",
    "\n",
    "def _on_click(_):\n",
    "    with out:\n",
    "        out.clear_output()\n",
    "        h, w = size_dropdown.value\n",
    "        images = run_sdxl_deis(\n",
    "            prompt=prompt_box.value,\n",
    "            nfe=int(nfe_slider.value),\n",
    "            guidance=float(guidance_slider.value),\n",
    "            h=h, w=w,\n",
    "            num_images=int(num_images_slider.value),\n",
    "        )\n",
    "        _show_images(images, cols=2)\n",
    "\n",
    "btn.on_click(_on_click)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<b>SDXL generation with DEIS scheduler</b>\"),\n",
    "    prompt_box,\n",
    "    nfe_slider,\n",
    "    guidance_slider,\n",
    "    size_dropdown,\n",
    "    num_images_slider,\n",
    "    btn,\n",
    "    out\n",
    "]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f405c0b",
   "metadata": {},
   "source": [
    "## Этические аспекты генеративного ИИ\n",
    "\n",
    "Этические и социальные эффекты генеративных моделей нельзя корректно анализировать в отрыве от их математической постановки. Генеративный ИИ не является системой принятия нормативных решений; он представляет собой механизм приближения эмпирического распределения данных \\(p^*(x)\\) некоторым параметрическим распределением \\(p_\\theta(x)\\), обучаемым по принципу максимизации правдоподобия или его вариационных/неявных аналогов.\n",
    "\n",
    "Следовательно, любые эффекты, возникающие при применении таких моделей, в первую очередь обусловлены **свойствами обучающего распределения, способом его аппроксимации и режимом использования сэмплов**, а не «намерениями» или «ошибками» модели как таковой.\n",
    "\n",
    "---\n",
    "\n",
    "### Генеративная модель как статистический репликатор данных\n",
    "\n",
    "В пределе оптимизации генеративная модель стремится воспроизвести структуру распределения \\(p^*(x)\\) в KL-смысле:\n",
    "\\[\n",
    "p_\\theta \\approx p^*.\n",
    "\\]\n",
    "Это утверждение принципиально: модель воспроизводит *частоты*, *корреляции* и *модальности* данных ровно в той мере, в какой они представлены в выборке.\n",
    "\n",
    "Отсюда следует фундаментальный вывод: **генеративная модель не “исправляет” данные и не “очищает” их от социальных или семантических перекосов**, а напротив — корректно их аппроксимирует. Любые систематические смещения (bias), присутствующие в данных, являются статистически значимой частью \\(p^*(x)\\) и, следовательно, переносятся в \\(p_\\theta(x)\\).\n",
    "\n",
    "В этом смысле генеративный ИИ является *усилителем* существующих структур данных, а не их интерпретатором.\n",
    "\n",
    "---\n",
    "\n",
    "### Bias и fairness как внешние ограничения, а не свойства модели\n",
    "\n",
    "Понятия bias и fairness не являются внутренними характеристиками вероятностной модели. Они определяются **вне** вероятностной постановки — через социальные, правовые или прикладные требования к допустимым результатам генерации.\n",
    "\n",
    "Если модель обучена на данных с неравномерным представлением групп, ролей или атрибутов, то воспроизведение этого неравенства является статистически корректным результатом обучения. С точки зрения MLE или ELBO здесь нет ошибки оптимизации.\n",
    "\n",
    "Таким образом, требования fairness могут быть реализованы только как:\n",
    "- модификация обучающего распределения (reweighting, filtering);\n",
    "- дополнительные ограничения на модель или пространство генерации;\n",
    "- пост-обработка сэмплов;\n",
    "- или контекстно-зависимые правила использования модели.\n",
    "\n",
    "Важно подчеркнуть: **fairness — это не цель генеративного обучения**, а дополнительное нормативное ограничение, которое должно быть задано явно и не выводится из вероятностной модели автоматически.\n",
    "\n",
    "---\n",
    "\n",
    "### Правдоподобие против истинности: природа галлюцинаций\n",
    "\n",
    "Генеративная модель оптимизирует правдоподобие, а не истинность. Это означает, что сэмпл \\(x\\sim p_\\theta(x)\\) считается “качественным”, если он:\n",
    "- статистически типичен;\n",
    "- согласован с контекстом;\n",
    "- лежит в области высокой плотности распределения.\n",
    "\n",
    "Проверка фактической корректности, каузальной согласованности или соответствия внешней реальности в эту постановку не входит. Поэтому явление, называемое *hallucinations*, представляет собой не сбой, а **естественное следствие вероятностной генерации в условиях неполной или противоречивой информации**.\n",
    "\n",
    "Особенно остро это проявляется в языковых моделях, где пространство допустимых последовательностей чрезвычайно велико, а множество “правдоподобных, но ложных” утверждений имеет ненулевую вероятность. С точки зрения модели, такие утверждения являются допустимыми сэмплами из \\(p_\\theta(x)\\).\n",
    "\n",
    "Следовательно, борьба с галлюцинациями не может быть сведена к “улучшению архитектуры” и требует либо внешних механизмов верификации, либо жёсткого разделения между генерацией и утверждением фактов.\n",
    "\n",
    "---\n",
    "\n",
    "### Масштабирование дезинформации как системный эффект\n",
    "\n",
    "Классическая дезинформация была ограничена стоимостью производства контента. Генеративные модели снимают это ограничение, позволяя масштабировать генерацию правдоподобных текстов, изображений и видео практически без затрат.\n",
    "\n",
    "С точки зрения вероятностной модели это означает следующее: если \\(p_\\theta(x)\\) хорошо аппроксимирует распределение “естественного” контента, то многократное семплирование из \\(p_\\theta\\) способно статистически изменить информационную среду, даже если каждый отдельный сэмпл неотличим от реального.\n",
    "\n",
    "Ключевым фактором здесь является **масштаб**, а не качество единичной генерации. Генеративный ИИ превращает дезинформацию из точечного инструмента в системное явление.\n",
    "\n",
    "---\n",
    "\n",
    "### Deepfake и условная генерация идентичностей\n",
    "\n",
    "Deepfake-технологии являются частным случаем условной генерации:\n",
    "\\[\n",
    "x \\sim p_\\theta(x \\mid y),\n",
    "\\]\n",
    "где условие \\(y\\) кодирует признаки конкретного человека (внешность, голос, манеру речи).\n",
    "\n",
    "С математической точки зрения deepfake не вводит новых механизмов по сравнению с другими формами conditional generation. Отличие заключается в **семантике условия**: условие соответствует реальной личности, а результат генерации может быть воспринят как документальное свидетельство.\n",
    "\n",
    "Этический риск возникает не на уровне модели, а на уровне интерпретации и применения: когда сэмплы генеративной модели выходят за рамки художественного или синтетического контекста и начинают функционировать как утверждения о реальных людях и событиях.\n",
    "\n",
    "---\n",
    "\n",
    "### Заключительная рамка\n",
    "\n",
    "Этические проблемы генеративного ИИ не являются аномалиями или побочными эффектами. Они логически следуют из самой идеи вероятностного моделирования данных.\n",
    "\n",
    "Генеративная модель:\n",
    "- не различает норму и отклонение;\n",
    "- не оптимизирует истинность или справедливость;\n",
    "- не несёт встроенных социальных ограничений.\n",
    "\n",
    "Поэтому этика в генеративном ИИ должна рассматриваться как **часть дизайна системы в целом** — включая данные, обучение, инференс и сценарии применения, — а не как свойство отдельной нейросетевой архитектуры.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
